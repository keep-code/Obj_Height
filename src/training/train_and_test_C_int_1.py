#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨ - å®Œæ•´çš„æ•´å‹Cè¯­è¨€è½¬æ¢ç‰ˆæœ¬
åŒ…å«LightGBMæ¨¡å‹è®­ç»ƒå’Œè‡ªåŠ¨Cè¯­è¨€æ•´å‹è½¬æ¢åŠŸèƒ½
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import joblib
import os
import json
from datetime import datetime
import math

warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibæ”¯æŒä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class LightGBMToCIntegerConverter:
    """LightGBMæ¨¡å‹è½¬Cè¯­è¨€æ•´å‹ä»£ç ç”Ÿæˆå™¨"""

    def __init__(self, model, feature_names, output_dir="./c_model_integer", scale_factor=10000):
        """
        åˆå§‹åŒ–è½¬æ¢å™¨

        Parameters:
        -----------
        model : LightGBM model
            è®­ç»ƒå¥½çš„LightGBMæ¨¡å‹
        feature_names : list
            ç‰¹å¾åç§°åˆ—è¡¨
        output_dir : str
            è¾“å‡ºç›®å½•
        scale_factor : int
            å®šç‚¹æ•°ç¼©æ”¾å› å­ï¼Œç”¨äºå°†æµ®ç‚¹æ•°è½¬æ¢ä¸ºæ•´æ•°
            ä¾‹å¦‚ï¼šscale_factor=10000è¡¨ç¤ºç²¾åº¦ä¸º0.0001
        """
        print(f"ğŸ” åˆå§‹åŒ–Cè¯­è¨€æ•´å‹è½¬æ¢å™¨...")
        print(f"   - æ¨¡å‹ç±»å‹: {type(model)}")
        print(f"   - ç‰¹å¾æ•°é‡: {len(feature_names)}")
        print(f"   - è¾“å‡ºç›®å½•: {output_dir}")
        print(f"   - ç¼©æ”¾å› å­: {scale_factor} (ç²¾åº¦: {1.0 / scale_factor})")

        self.model = model
        self.feature_names = feature_names
        self.output_dir = output_dir
        self.scale_factor = scale_factor
        self.num_features = len(feature_names)
        self.num_trees = 0
        self.trees = []
        self.objective = 'binary'

        # åˆ›å»ºè¾“å‡ºç›®å½•
        try:
            os.makedirs(output_dir, exist_ok=True)
            print(f"âœ… è¾“å‡ºç›®å½•åˆ›å»ºæˆåŠŸ: {output_dir}")
        except Exception as e:
            print(f"âŒ è¾“å‡ºç›®å½•åˆ›å»ºå¤±è´¥: {e}")
            raise

    def float_to_fixed(self, value):
        """å°†æµ®ç‚¹æ•°è½¬æ¢ä¸ºå®šç‚¹æ•°æ•´å‹"""
        return int(round(value * self.scale_factor))

    def extract_model_info(self):
        """æå–æ¨¡å‹ä¿¡æ¯"""
        print(f"ğŸ” æå–æ¨¡å‹ä¿¡æ¯...")

        try:
            if not hasattr(self.model, 'dump_model'):
                raise ValueError(f"æ¨¡å‹ç±»å‹ {type(self.model)} ä¸æ”¯æŒdump_modelæ–¹æ³•")

            model_dict = self.model.dump_model()
            print(f"âœ… æ¨¡å‹ä¿¡æ¯æå–æˆåŠŸ")

            self.num_trees = model_dict.get('num_tree_per_iteration', 1)
            self.trees = model_dict.get('tree_info', [])
            self.objective = model_dict.get('objective', 'binary')

            print(f"ğŸ“Š æ¨¡å‹è¯¦ç»†ä¿¡æ¯:")
            print(f"   - æ ‘çš„æ•°é‡: {len(self.trees)}")
            print(f"   - æ¯æ¬¡è¿­ä»£æ ‘æ•°: {self.num_trees}")
            print(f"   - ç‰¹å¾æ•°é‡: {self.num_features}")
            print(f"   - ç›®æ ‡å‡½æ•°: {self.objective}")

            return model_dict

        except Exception as e:
            print(f"âŒ æ¨¡å‹ä¿¡æ¯æå–å¤±è´¥: {e}")
            raise

    def generate_tree_function(self, tree_dict, tree_id):
        """ç”Ÿæˆå•ä¸ªæ ‘çš„Cå‡½æ•°ï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰"""
        print(f"ğŸŒ³ ç”Ÿæˆç¬¬ {tree_id} æ£µæ ‘ï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰...")

        try:
            def generate_node_code(node, indent=0):
                """é€’å½’ç”ŸæˆèŠ‚ç‚¹ä»£ç ï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰"""
                spaces = "    " * indent

                if 'leaf_value' in node:
                    leaf_value = node['leaf_value']
                    leaf_value_fixed = self.float_to_fixed(leaf_value)
                    return f"{spaces}return {leaf_value_fixed};\n"
                else:
                    feature_idx = node['split_feature']
                    threshold = node['threshold']
                    threshold_fixed = self.float_to_fixed(threshold)
                    left_child = node['left_child']
                    right_child = node['right_child']

                    if feature_idx >= self.num_features:
                        raise ValueError(f"ç‰¹å¾ç´¢å¼• {feature_idx} è¶…å‡ºèŒƒå›´ [0, {self.num_features - 1}]")

                    code = f"{spaces}if (features[{feature_idx}] <= {threshold_fixed}) {{\n"
                    code += generate_node_code(left_child, indent + 1)
                    code += f"{spaces}}} else {{\n"
                    code += generate_node_code(right_child, indent + 1)
                    code += f"{spaces}}}\n"

                    return code

            if 'tree_structure' not in tree_dict:
                raise ValueError(f"æ ‘ {tree_id} ç¼ºå°‘ tree_structure")

            tree_structure = tree_dict['tree_structure']

            func_code = f"""
static int32_t tree_{tree_id}(const int32_t *features) {{
{generate_node_code(tree_structure, 1)}}}
"""
            print(f"âœ… ç¬¬ {tree_id} æ£µæ ‘ç”ŸæˆæˆåŠŸï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰")
            return func_code

        except Exception as e:
            print(f"âŒ ç¬¬ {tree_id} æ£µæ ‘ç”Ÿæˆå¤±è´¥: {e}")
            raise

    def generate_prediction_function(self):
        """ç”Ÿæˆé¢„æµ‹å‡½æ•°ï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰"""
        print(f"ğŸ”® ç”Ÿæˆé¢„æµ‹å‡½æ•°ï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰...")

        try:
            tree_calls = []
            for i in range(len(self.trees)):
                tree_calls.append(f"    sum += tree_{i}(features);")

            tree_calls_str = "\n".join(tree_calls)

            # ç”Ÿæˆæ•´å‹ç‰ˆæœ¬çš„sigmoidæŸ¥æ‰¾è¡¨
            sigmoid_table_size = 1000
            sigmoid_table = []
            for i in range(sigmoid_table_size + 1):
                x = (i - sigmoid_table_size // 2) * 20.0 / sigmoid_table_size  # èŒƒå›´å¤§çº¦æ˜¯-10åˆ°10
                sigmoid_val = 1.0 / (1.0 + math.exp(-x))
                sigmoid_table.append(self.float_to_fixed(sigmoid_val))

            sigmoid_table_str = ",\n    ".join([str(val) for val in sigmoid_table])

            prediction_code = f"""
// SigmoidæŸ¥æ‰¾è¡¨ (å®šç‚¹æ•°æ ¼å¼ï¼Œç¼©æ”¾å› å­: {self.scale_factor})
static const int32_t sigmoid_table[{sigmoid_table_size + 1}] = {{
    {sigmoid_table_str}
}};

#define SIGMOID_TABLE_SIZE {sigmoid_table_size}
#define SIGMOID_INPUT_SCALE 20
#define SIGMOID_INPUT_OFFSET {sigmoid_table_size // 2}

int32_t predict_raw(const int32_t *features) {{
    int64_t sum = 0;  // ä½¿ç”¨64ä½é¿å…æº¢å‡º
{tree_calls_str}
    return (int32_t)sum;
}}

int32_t predict_probability_fixed(const int32_t *features) {{
    int32_t raw_score = predict_raw(features);

    // å°†åŸå§‹åˆ†æ•°æ˜ å°„åˆ°æŸ¥æ‰¾è¡¨ç´¢å¼•
    // raw_scoreæ˜¯å®šç‚¹æ•°æ ¼å¼ï¼Œéœ€è¦è½¬æ¢åˆ°åˆé€‚çš„èŒƒå›´
    int32_t table_input = (raw_score * SIGMOID_INPUT_SCALE) / {self.scale_factor} + SIGMOID_INPUT_OFFSET;

    // è¾¹ç•Œæ£€æŸ¥
    if (table_input < 0) table_input = 0;
    if (table_input > SIGMOID_TABLE_SIZE) table_input = SIGMOID_TABLE_SIZE;

    return sigmoid_table[table_input];
}}

int predict_class(const int32_t *features) {{
    int32_t prob = predict_probability_fixed(features);
    return prob > {self.scale_factor // 2} ? 1 : 0;  // é˜ˆå€¼0.5å¯¹åº”çš„å®šç‚¹æ•°
}}

int32_t predict_confidence_fixed(const int32_t *features) {{
    int32_t prob = predict_probability_fixed(features);
    int32_t half_scale = {self.scale_factor // 2};
    int32_t diff = prob > half_scale ? (prob - half_scale) : (half_scale - prob);
    return diff * 2;  // è½¬æ¢ä¸º0-1çš„ç½®ä¿¡åº¦
}}

// æµ®ç‚¹æ•°ç‰ˆæœ¬çš„æ¥å£ï¼ˆç”¨äºè°ƒè¯•å’ŒéªŒè¯ï¼‰
double predict_probability_float(const int32_t *features) {{
    return (double)predict_probability_fixed(features) / {self.scale_factor};
}}

double predict_confidence_float(const int32_t *features) {{
    return (double)predict_confidence_fixed(features) / {self.scale_factor};
}}

double predict_raw_float(const int32_t *features) {{
    return (double)predict_raw(features) / {self.scale_factor};
}}
"""
            print(f"âœ… é¢„æµ‹å‡½æ•°ç”ŸæˆæˆåŠŸï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰")
            return prediction_code

        except Exception as e:
            print(f"âŒ é¢„æµ‹å‡½æ•°ç”Ÿæˆå¤±è´¥: {e}")
            raise

    def write_file(self, filepath, content):
        """å†™å…¥æ–‡ä»¶"""
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)

            if os.path.exists(filepath):
                file_size = os.path.getsize(filepath)
                print(f"âœ… æ–‡ä»¶å†™å…¥æˆåŠŸ: {os.path.basename(filepath)} ({file_size} bytes)")
                return True
            else:
                print(f"âŒ æ–‡ä»¶å†™å…¥å¤±è´¥: {os.path.basename(filepath)} (æ–‡ä»¶ä¸å­˜åœ¨)")
                return False

        except Exception as e:
            print(f"âŒ æ–‡ä»¶å†™å…¥å¤±è´¥: {os.path.basename(filepath)}")
            print(f"   é”™è¯¯: {e}")
            return False

    def convert(self):
        """æ‰§è¡Œè½¬æ¢"""
        print(f"\nğŸš€ å¼€å§‹è½¬æ¢LightGBMæ¨¡å‹åˆ°Cè¯­è¨€ï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰...")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"ğŸ”¢ ç¼©æ”¾å› å­: {self.scale_factor}")
        print(f"{'=' * 60}")

        try:
            # æ£€æŸ¥è¾“å‡ºç›®å½•æƒé™
            if not os.path.exists(self.output_dir):
                print(f"âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {self.output_dir}")
                return False

            if not os.access(self.output_dir, os.W_OK):
                print(f"âŒ è¾“å‡ºç›®å½•æ— å†™å…¥æƒé™: {self.output_dir}")
                return False

            print(f"âœ… è¾“å‡ºç›®å½•æ£€æŸ¥é€šè¿‡")

            # æå–æ¨¡å‹ä¿¡æ¯
            self.extract_model_info()

            # ç”Ÿæˆå¤´æ–‡ä»¶
            print(f"\n1ï¸âƒ£ ç”Ÿæˆå¤´æ–‡ä»¶...")
            header_content = self.generate_header_file()
            header_file = os.path.join(self.output_dir, "obstacle_height_model_int.h")
            if not self.write_file(header_file, header_content):
                return False

            # ç”Ÿæˆæºæ–‡ä»¶
            print(f"\n2ï¸âƒ£ ç”Ÿæˆæºæ–‡ä»¶...")
            source_content = self.generate_source_file()
            source_file = os.path.join(self.output_dir, "obstacle_height_model_int.c")
            if not self.write_file(source_file, source_content):
                return False

            # ç”Ÿæˆæµ‹è¯•æ–‡ä»¶
            print(f"\n3ï¸âƒ£ ç”Ÿæˆæµ‹è¯•æ–‡ä»¶...")
            test_content = self.generate_test_file()
            test_file = os.path.join(self.output_dir, "test_obstacle_height_int.c")
            if not self.write_file(test_file, test_content):
                return False

            # ç”ŸæˆMakefile
            print(f"\n4ï¸âƒ£ ç”ŸæˆMakefile...")
            makefile_content = self.generate_makefile()
            makefile_file = os.path.join(self.output_dir, "Makefile")
            if not self.write_file(makefile_file, makefile_content):
                return False

            # ä¿å­˜ç‰¹å¾æ˜ å°„
            print(f"\n5ï¸âƒ£ ä¿å­˜ç‰¹å¾æ˜ å°„...")
            if not self.save_feature_mapping():
                return False

            # ç”Ÿæˆæ•°æ®è½¬æ¢å·¥å…·
            print(f"\n6ï¸âƒ£ ç”Ÿæˆæ•°æ®è½¬æ¢å·¥å…·...")
            if not self.generate_data_converter():
                return False

            # ç”Ÿæˆä½¿ç”¨è¯´æ˜
            print(f"\n7ï¸âƒ£ ç”Ÿæˆä½¿ç”¨è¯´æ˜...")
            if not self.generate_usage_guide():
                return False

            print(f"\nğŸ‰ æ•´å‹ç‰ˆæœ¬è½¬æ¢å®Œæˆ!")
            return True

        except Exception as e:
            print(f"\nâŒ è½¬æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def generate_header_file(self):
        """ç”Ÿæˆå¤´æ–‡ä»¶ï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰"""
        header_content = f"""#ifndef OBSTACLE_HEIGHT_MODEL_INT_H
#define OBSTACLE_HEIGHT_MODEL_INT_H

#include <stdint.h>

// æ¨¡å‹ä¿¡æ¯
#define NUM_FEATURES {self.num_features}
#define NUM_TREES {len(self.trees)}
#define SCALE_FACTOR {self.scale_factor}
#define PRECISION_DIGITS {len(str(self.scale_factor)) - 1}

// ç‰¹å¾ç´¢å¼•å®šä¹‰
"""
        for i, feature_name in enumerate(self.feature_names):
            feature_macro = (feature_name.upper()
                             .replace(' ', '_')
                             .replace('-', '_')
                             .replace('(', '')
                             .replace(')', '')
                             .replace('.', '_')
                             .replace('/', '_'))
            header_content += f"#define FEATURE_{feature_macro} {i}\n"

        header_content += f"""
// å®šç‚¹æ•°è½¬æ¢å®
#define FLOAT_TO_FIXED(x) ((int32_t)((x) * SCALE_FACTOR))
#define FIXED_TO_FLOAT(x) ((double)(x) / SCALE_FACTOR)

// æ•´å‹é¢„æµ‹å‡½æ•°
int32_t predict_raw(const int32_t *features);
int32_t predict_probability_fixed(const int32_t *features);
int predict_class(const int32_t *features);
int32_t predict_confidence_fixed(const int32_t *features);

// æµ®ç‚¹æ•°æ¥å£ï¼ˆç”¨äºè°ƒè¯•ï¼‰
double predict_probability_float(const int32_t *features);
double predict_confidence_float(const int32_t *features);
double predict_raw_float(const int32_t *features);

// æ•°æ®è½¬æ¢è¾…åŠ©å‡½æ•°
void convert_float_features_to_fixed(const double *float_features, int32_t *fixed_features);

// é¢„æµ‹ç»“æœç»“æ„ä½“ï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰
typedef struct {{
    int height_label;
    int32_t probability_fixed;
    int32_t confidence_fixed;
    int32_t raw_score_fixed;
    double probability_float;  // è°ƒè¯•ç”¨
    double confidence_float;   // è°ƒè¯•ç”¨
    double raw_score_float;    // è°ƒè¯•ç”¨
}} ObstacleHeightPredictionInt;

ObstacleHeightPredictionInt predict_obstacle_height_int(const int32_t *features);
ObstacleHeightPredictionInt predict_obstacle_height_from_float(const double *float_features);

#endif // OBSTACLE_HEIGHT_MODEL_INT_H
"""
        return header_content

    def generate_source_file(self):
        """ç”Ÿæˆæºæ–‡ä»¶ï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        source_content = f"""/*
 * éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨ - LightGBMæ¨¡å‹Cè¯­è¨€æ•´å‹å®ç°
 * ç”Ÿæˆæ—¶é—´: {timestamp}
 * ç‰¹å¾æ•°é‡: {self.num_features}
 * æ ‘çš„æ•°é‡: {len(self.trees)}
 * ç¼©æ”¾å› å­: {self.scale_factor}
 * ç²¾åº¦: {1.0 / self.scale_factor}
 */

#include "obstacle_height_model_int.h"
#include <math.h>

"""

        # ç”Ÿæˆæ‰€æœ‰æ ‘çš„å‡½æ•°
        print(f"ğŸŒ³ å¼€å§‹ç”Ÿæˆ {len(self.trees)} æ£µæ ‘ï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰...")
        for i, tree in enumerate(self.trees):
            tree_func = self.generate_tree_function(tree, i)
            source_content += tree_func

        # ç”Ÿæˆé¢„æµ‹å‡½æ•°
        prediction_func = self.generate_prediction_function()
        source_content += prediction_func

        # ç”Ÿæˆä¾¿åˆ©å‡½æ•°
        source_content += f"""
void convert_float_features_to_fixed(const double *float_features, int32_t *fixed_features) {{
    for (int i = 0; i < NUM_FEATURES; i++) {{
        fixed_features[i] = FLOAT_TO_FIXED(float_features[i]);
    }}
}}

ObstacleHeightPredictionInt predict_obstacle_height_int(const int32_t *features) {{
    ObstacleHeightPredictionInt result;
    result.raw_score_fixed = predict_raw(features);
    result.probability_fixed = predict_probability_fixed(features);
    result.height_label = predict_class(features);
    result.confidence_fixed = predict_confidence_fixed(features);

    // ç”Ÿæˆæµ®ç‚¹æ•°ç‰ˆæœ¬ç”¨äºè°ƒè¯•
    result.raw_score_float = FIXED_TO_FLOAT(result.raw_score_fixed);
    result.probability_float = FIXED_TO_FLOAT(result.probability_fixed);
    result.confidence_float = FIXED_TO_FLOAT(result.confidence_fixed);

    return result;
}}

ObstacleHeightPredictionInt predict_obstacle_height_from_float(const double *float_features) {{
    int32_t fixed_features[NUM_FEATURES];
    convert_float_features_to_fixed(float_features, fixed_features);
    return predict_obstacle_height_int(fixed_features);
}}
"""

        return source_content

    def generate_test_file(self):
        """ç”Ÿæˆæµ‹è¯•æ–‡ä»¶ï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰"""
        test_content = f"""/*
 * éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨æµ‹è¯•ç¨‹åºï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰
 */

#include <stdio.h>
#include <stdlib.h>
#include "obstacle_height_model_int.h"

void test_integer_prediction() {{
    printf("=== æ•´å‹é¢„æµ‹æµ‹è¯• ===\\n");

    // ç¤ºä¾‹æµ‹è¯•æ•°æ®ï¼ˆæ•´å‹å®šç‚¹æ•°æ ¼å¼ï¼‰
    int32_t fixed_features[NUM_FEATURES] = {{0}};

    // è®¾ç½®ä¸€äº›ç¤ºä¾‹å€¼ï¼ˆå·²ç»æ˜¯å®šç‚¹æ•°æ ¼å¼ï¼‰
    for(int i = 0; i < NUM_FEATURES && i < 10; i++) {{
        fixed_features[i] = FLOAT_TO_FIXED(i * 100 + 200);
    }}

    printf("è¾“å…¥ç‰¹å¾ï¼ˆå‰10ä¸ªï¼‰:\\n");
    for(int i = 0; i < NUM_FEATURES && i < 10; i++) {{
        printf("ç‰¹å¾%d: %d (%.6f)\\n", i, fixed_features[i], FIXED_TO_FLOAT(fixed_features[i]));
    }}

    ObstacleHeightPredictionInt result = predict_obstacle_height_int(fixed_features);

    printf("\\næ•´å‹é¢„æµ‹ç»“æœ:\\n");
    printf("- é«˜åº¦æ ‡ç­¾: %d (%s)\\n", result.height_label, 
           result.height_label ? "é«˜éšœç¢ç‰©" : "ä½éšœç¢ç‰©");
    printf("- æ¦‚ç‡(å®šç‚¹æ•°): %d\\n", result.probability_fixed);
    printf("- æ¦‚ç‡(æµ®ç‚¹æ•°): %.6f\\n", result.probability_float);
    printf("- ç½®ä¿¡åº¦(å®šç‚¹æ•°): %d\\n", result.confidence_fixed);
    printf("- ç½®ä¿¡åº¦(æµ®ç‚¹æ•°): %.6f\\n", result.confidence_float);
    printf("- åŸå§‹åˆ†æ•°(å®šç‚¹æ•°): %d\\n", result.raw_score_fixed);
    printf("- åŸå§‹åˆ†æ•°(æµ®ç‚¹æ•°): %.6f\\n", result.raw_score_float);
}}

void test_float_to_fixed_conversion() {{
    printf("\\n=== æµ®ç‚¹æ•°è½¬æ¢æµ‹è¯• ===\\n");

    // æµ‹è¯•æµ®ç‚¹æ•°ç‰¹å¾
    double float_features[NUM_FEATURES] = {{0.0}};

    // è®¾ç½®ä¸€äº›ç¤ºä¾‹å€¼
    for(int i = 0; i < NUM_FEATURES && i < 10; i++) {{
        float_features[i] = (double)(i * 100 + 200);
    }}

    printf("æµ®ç‚¹æ•°è¾“å…¥ç‰¹å¾ï¼ˆå‰10ä¸ªï¼‰:\\n");
    for(int i = 0; i < NUM_FEATURES && i < 10; i++) {{
        printf("ç‰¹å¾%d: %.6f\\n", i, float_features[i]);
    }}

    ObstacleHeightPredictionInt result = predict_obstacle_height_from_float(float_features);

    printf("\\nä»æµ®ç‚¹æ•°è½¬æ¢åçš„é¢„æµ‹ç»“æœ:\\n");
    printf("- é«˜åº¦æ ‡ç­¾: %d (%s)\\n", result.height_label, 
           result.height_label ? "é«˜éšœç¢ç‰©" : "ä½éšœç¢ç‰©");
    printf("- æ¦‚ç‡: %.6f\\n", result.probability_float);
    printf("- ç½®ä¿¡åº¦: %.6f\\n", result.confidence_float);
    printf("- åŸå§‹åˆ†æ•°: %.6f\\n", result.raw_score_float);
}}

void test_precision() {{
    printf("\\n=== ç²¾åº¦æµ‹è¯• ===\\n");
    printf("ç¼©æ”¾å› å­: %d\\n", SCALE_FACTOR);
    printf("ç†è®ºç²¾åº¦: %.8f\\n", 1.0 / SCALE_FACTOR);

    // æµ‹è¯•ä¸€äº›å…³é”®å€¼çš„è½¬æ¢ç²¾åº¦
    double test_values[] = {{0.0, 0.5, 1.0, 0.1, 0.9, 0.123456}};
    int num_test_values = sizeof(test_values) / sizeof(test_values[0]);

    printf("\\nè½¬æ¢ç²¾åº¦æµ‹è¯•:\\n");
    for(int i = 0; i < num_test_values; i++) {{
        double original = test_values[i];
        int32_t fixed = FLOAT_TO_FIXED(original);
        double recovered = FIXED_TO_FLOAT(fixed);
        double error = fabs(original - recovered);

        printf("åŸå€¼: %.6f -> å®šç‚¹æ•°: %d -> æ¢å¤å€¼: %.6f, è¯¯å·®: %.8f\\n",
               original, fixed, recovered, error);
    }}
}}

int main() {{
    printf("=== éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨ Cè¯­è¨€æ•´å‹ç‰ˆæœ¬ ===\\n");
    printf("ç‰¹å¾æ•°é‡: %d\\n", NUM_FEATURES);
    printf("æ ‘çš„æ•°é‡: %d\\n", NUM_TREES);
    printf("ç¼©æ”¾å› å­: %d\\n", SCALE_FACTOR);
    printf("\\n");

    test_precision();
    test_integer_prediction();
    test_float_to_fixed_conversion();

    return 0;
}}
"""
        return test_content

    def generate_makefile(self):
        """ç”ŸæˆMakefileï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰"""
        return """# éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨ Makefile (æ•´å‹ç‰ˆæœ¬)

CC = gcc
CFLAGS = -Wall -O2 -std=c99
LDFLAGS = -lm

TARGET = test_obstacle_height_int
SOURCES = obstacle_height_model_int.c test_obstacle_height_int.c
HEADERS = obstacle_height_model_int.h

all: $(TARGET)

$(TARGET): $(SOURCES) $(HEADERS)
	$(CC) $(CFLAGS) -o $(TARGET) $(SOURCES) $(LDFLAGS)

clean:
	rm -f $(TARGET)

.PHONY: all clean
"""

    def save_feature_mapping(self):
        """ä¿å­˜ç‰¹å¾æ˜ å°„ï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰"""
        try:
            feature_mapping = {
                "feature_names": self.feature_names,
                "feature_count": self.num_features,
                "scale_factor": self.scale_factor,
                "precision": 1.0 / self.scale_factor,
                "model_info": {
                    "trees": len(self.trees),
                    "objective": self.objective,
                    "data_type": "int32_t"
                }
            }

            mapping_file = os.path.join(self.output_dir, "feature_mapping_int.json")
            return self.write_file(mapping_file, json.dumps(feature_mapping, indent=2, ensure_ascii=False))

        except Exception as e:
            print(f"âŒ ç‰¹å¾æ˜ å°„ä¿å­˜å¤±è´¥: {e}")
            return False

    def generate_data_converter(self):
        """ç”Ÿæˆæ•°æ®è½¬æ¢å·¥å…·"""
        try:
            converter_content = f"""/*
 * æ•°æ®è½¬æ¢å·¥å…· - æµ®ç‚¹æ•°åˆ°å®šç‚¹æ•°è½¬æ¢
 * ç¼©æ”¾å› å­: {self.scale_factor}
 */

#include <stdio.h>
#include <stdlib.h>
#include "obstacle_height_model_int.h"

// æ‰¹é‡è½¬æ¢æµ®ç‚¹æ•°ç‰¹å¾åˆ°å®šç‚¹æ•°
void batch_convert_features(const double *float_batch, int32_t *fixed_batch, int num_samples) {{
    for (int sample = 0; sample < num_samples; sample++) {{
        for (int feature = 0; feature < NUM_FEATURES; feature++) {{
            int input_idx = sample * NUM_FEATURES + feature;
            int output_idx = sample * NUM_FEATURES + feature;
            fixed_batch[output_idx] = FLOAT_TO_FIXED(float_batch[input_idx]);
        }}
    }}
}}

// ä»CSVæ–‡ä»¶è¯»å–å¹¶è½¬æ¢æ•°æ®ï¼ˆç¤ºä¾‹å‡½æ•°ï¼‰
int convert_csv_to_fixed(const char *input_csv, const char *output_file) {{
    FILE *input = fopen(input_csv, "r");
    FILE *output = fopen(output_file, "w");

    if (!input || !output) {{
        printf("æ–‡ä»¶æ‰“å¼€å¤±è´¥\\n");
        return -1;
    }}

    char line[4096];
    int line_num = 0;

    // å†™å…¥å¤´éƒ¨ä¿¡æ¯
    fprintf(output, "# è½¬æ¢åçš„å®šç‚¹æ•°ç‰¹å¾æ–‡ä»¶\\n");
    fprintf(output, "# ç¼©æ”¾å› å­: %d\\n", SCALE_FACTOR);
    fprintf(output, "# ç‰¹å¾æ•°é‡: %d\\n", NUM_FEATURES);
    fprintf(output, "\\n");

    while (fgets(line, sizeof(line), input)) {{
        line_num++;
        if (line_num == 1) continue; // è·³è¿‡æ ‡é¢˜è¡Œ

        double features[NUM_FEATURES];
        int32_t fixed_features[NUM_FEATURES];

        // è§£æCSVè¡Œï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…ä½¿ç”¨æ—¶å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è§£æï¼‰
        char *token = strtok(line, ",");
        int feature_idx = 0;

        while (token && feature_idx < NUM_FEATURES) {{
            features[feature_idx] = atof(token);
            feature_idx++;
            token = strtok(NULL, ",");
        }}

        // è½¬æ¢ä¸ºå®šç‚¹æ•°
        convert_float_features_to_fixed(features, fixed_features);

        // å†™å…¥è¾“å‡ºæ–‡ä»¶
        for (int i = 0; i < NUM_FEATURES; i++) {{
            fprintf(output, "%d", fixed_features[i]);
            if (i < NUM_FEATURES - 1) fprintf(output, ",");
        }}
        fprintf(output, "\\n");
    }}

    fclose(input);
    fclose(output);

    printf("è½¬æ¢å®Œæˆï¼Œå¤„ç†äº† %d è¡Œæ•°æ®\\n", line_num - 1);
    return 0;
}}

int main(int argc, char *argv[]) {{
    if (argc < 3) {{
        printf("ç”¨æ³•: %s <è¾“å…¥CSVæ–‡ä»¶> <è¾“å‡ºæ–‡ä»¶>\\n", argv[0]);
        return 1;
    }}

    return convert_csv_to_fixed(argv[1], argv[2]);
}}
"""

            converter_file = os.path.join(self.output_dir, "data_converter.c")
            return self.write_file(converter_file, converter_content)

        except Exception as e:
            print(f"âŒ æ•°æ®è½¬æ¢å·¥å…·ç”Ÿæˆå¤±è´¥: {e}")
            return False

    def generate_usage_guide(self):
        """ç”Ÿæˆä½¿ç”¨è¯´æ˜ï¼ˆæ•´å‹ç‰ˆæœ¬ï¼‰"""
        try:
            guide_content = f"""# éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨ Cè¯­è¨€æ•´å‹ç‰ˆæœ¬

## æ¦‚è¿°
æœ¬ç‰ˆæœ¬ä¸“ä¸ºMCUç¯å¢ƒè®¾è®¡ï¼Œä½¿ç”¨32ä½æ•´å‹è¿›è¡Œæ‰€æœ‰è®¡ç®—ï¼Œé¿å…æµ®ç‚¹è¿ç®—ã€‚

## æŠ€æœ¯å‚æ•°
- **æ•°æ®ç±»å‹**: int32_t (32ä½æœ‰ç¬¦å·æ•´æ•°)
- **ç¼©æ”¾å› å­**: {self.scale_factor}
- **æ•°å€¼ç²¾åº¦**: {1.0 / self.scale_factor}
- **ç‰¹å¾æ•°é‡**: {self.num_features}
- **æ ‘çš„æ•°é‡**: {len(self.trees)}

## ç¼–è¯‘å’Œè¿è¡Œ
```bash
# ç¼–è¯‘æµ‹è¯•ç¨‹åº
make

# è¿è¡Œæµ‹è¯•
./test_obstacle_height_int

# ç¼–è¯‘æ•°æ®è½¬æ¢å·¥å…·
gcc -o data_converter data_converter.c obstacle_height_model_int.c -lm
```

## åœ¨MCUé¡¹ç›®ä¸­ä½¿ç”¨

### 1. åŸºæœ¬ä½¿ç”¨
```c
#include "obstacle_height_model_int.h"

// å®šä¹‰ç‰¹å¾æ•°ç»„ï¼ˆå®šç‚¹æ•°æ ¼å¼ï¼‰
int32_t features[NUM_FEATURES];

// è®¾ç½®ç‰¹å¾å€¼ï¼ˆéœ€è¦è½¬æ¢ä¸ºå®šç‚¹æ•°ï¼‰
features[0] = FLOAT_TO_FIXED(123.45);  // å°†æµ®ç‚¹æ•°è½¬æ¢ä¸ºå®šç‚¹æ•°
features[1] = FLOAT_TO_FIXED(67.89);

// è¿›è¡Œé¢„æµ‹
ObstacleHeightPredictionInt result = predict_obstacle_height_int(features);

if (result.height_label == 1) {{
    // æ£€æµ‹åˆ°é«˜éšœç¢ç‰©
    printf("é«˜éšœç¢ç‰©æ£€æµ‹ï¼ç½®ä¿¡åº¦: %d\\n", result.confidence_fixed);
}}
```

### 2. å¦‚æœè¾“å…¥æ˜¯æµ®ç‚¹æ•°
```c
double float_features[NUM_FEATURES] = {{123.45, 67.89, ...}};
ObstacleHeightPredictionInt result = predict_obstacle_height_from_float(float_features);
```

### 3. æ‰‹åŠ¨æ•°æ®è½¬æ¢
```c
// æµ®ç‚¹æ•°è½¬å®šç‚¹æ•°
double float_value = 123.456;
int32_t fixed_value = FLOAT_TO_FIXED(float_value);

// å®šç‚¹æ•°è½¬æµ®ç‚¹æ•°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
double recovered_value = FIXED_TO_FLOAT(fixed_value);
```

## å†…å­˜ä½¿ç”¨
- **ç‰¹å¾æ•°ç»„**: {self.num_features} Ã— 4 = {self.num_features * 4} å­—èŠ‚
- **é¢„æµ‹ç»“æœ**: çº¦ 32 å­—èŠ‚
- **sigmoidæŸ¥æ‰¾è¡¨**: çº¦ 4KB
- **ä»£ç å¤§å°**: é¢„è®¡ < 50KB

## æ€§èƒ½ç‰¹ç‚¹
- âœ… æ— æµ®ç‚¹è¿ç®—ï¼Œé€‚åˆæ— FPUçš„MCU
- âœ… æŸ¥æ‰¾è¡¨å®ç°sigmoidå‡½æ•°ï¼Œé€Ÿåº¦å¿«
- âœ… 32ä½æ•´å‹ï¼Œç²¾åº¦è¶³å¤Ÿ
- âœ… å†…å­˜å ç”¨å°

## ç²¾åº¦åˆ†æ
ä½¿ç”¨ {self.scale_factor} ä½œä¸ºç¼©æ”¾å› å­ï¼š
- æœ€å°è¡¨ç¤ºå€¼: {1.0 / self.scale_factor}
- æ•°å€¼èŒƒå›´: Â±{2 ** 31 // self.scale_factor}
- å¯¹äºéšœç¢ç‰©åˆ†ç±»ä»»åŠ¡ï¼Œæ­¤ç²¾åº¦é€šå¸¸è¶³å¤Ÿ

## ç‰¹å¾åˆ—è¡¨ ({self.num_features}ä¸ªç‰¹å¾)
"""
            for i, name in enumerate(self.feature_names):
                guide_content += f"{i:2d}: {name}\n"

            guide_content += f"""

## API å‚è€ƒ

### æ ¸å¿ƒé¢„æµ‹å‡½æ•°
```c
// åŸå§‹åˆ†æ•°é¢„æµ‹ï¼ˆå®šç‚¹æ•°ï¼‰
int32_t predict_raw(const int32_t *features);

// æ¦‚ç‡é¢„æµ‹ï¼ˆå®šç‚¹æ•°ï¼Œ0-{self.scale_factor}è¡¨ç¤º0-1ï¼‰
int32_t predict_probability_fixed(const int32_t *features);

// åˆ†ç±»é¢„æµ‹ï¼ˆ0æˆ–1ï¼‰
int predict_class(const int32_t *features);

// ç½®ä¿¡åº¦é¢„æµ‹ï¼ˆå®šç‚¹æ•°ï¼‰
int32_t predict_confidence_fixed(const int32_t *features);
```

### è¾…åŠ©å‡½æ•°
```c
// æ‰¹é‡ç‰¹å¾è½¬æ¢
void convert_float_features_to_fixed(const double *float_features, int32_t *fixed_features);

// å®Œæ•´é¢„æµ‹ï¼ˆæ¨èä½¿ç”¨ï¼‰
ObstacleHeightPredictionInt predict_obstacle_height_int(const int32_t *features);
ObstacleHeightPredictionInt predict_obstacle_height_from_float(const double *float_features);
```

## ç§»æ¤åˆ°MCUæ³¨æ„äº‹é¡¹

1. **åŒ…å«æ–‡ä»¶**: ç¡®ä¿ `stdint.h` å¯ç”¨
2. **æ•°å­¦åº“**: å¯èƒ½éœ€è¦ç§»é™¤ `math.h` ä¾èµ–
3. **å†…å­˜å¯¹é½**: æ³¨æ„32ä½æ•´æ•°çš„å†…å­˜å¯¹é½
4. **æŸ¥æ‰¾è¡¨**: sigmoid_tableå ç”¨çº¦4KB ROM

## è°ƒè¯•æŠ€å·§

1. **ç²¾åº¦éªŒè¯**:
   ```c
   test_precision(); // è¿è¡Œç²¾åº¦æµ‹è¯•
   ```

2. **ç»“æœå¯¹æ¯”**:
   ```c
   // åŒæ—¶æŸ¥çœ‹å®šç‚¹æ•°å’Œæµ®ç‚¹æ•°ç»“æœ
   printf("å®šç‚¹æ•°æ¦‚ç‡: %d, æµ®ç‚¹æ•°æ¦‚ç‡: %.6f\\n", 
          result.probability_fixed, result.probability_float);
   ```

3. **ç‰¹å¾æ£€æŸ¥**:
   ```c
   // æ£€æŸ¥ç‰¹å¾è½¬æ¢æ˜¯å¦æ­£ç¡®
   for(int i = 0; i < NUM_FEATURES; i++) {{
       printf("ç‰¹å¾%d: %d (%.6f)\\n", i, fixed_features[i], 
              FIXED_TO_FLOAT(fixed_features[i]));
   }}
   ```

## å¸¸è§é—®é¢˜

**Q: ä¸ºä»€ä¹ˆä½¿ç”¨å®šç‚¹æ•°ï¼Ÿ**
A: è®¸å¤šMCUæ²¡æœ‰æµ®ç‚¹è¿ç®—å•å…ƒ(FPU)ï¼Œå®šç‚¹æ•°è¿ç®—æ›´å¿«æ›´èŠ‚èƒ½ã€‚

**Q: ç²¾åº¦å¤Ÿç”¨å—ï¼Ÿ**
A: å¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œ{1.0 / self.scale_factor}çš„ç²¾åº¦é€šå¸¸è¶³å¤Ÿã€‚å¯ä»¥é€šè¿‡è°ƒæ•´SCALE_FACTORæ¥å¹³è¡¡ç²¾åº¦å’ŒèŒƒå›´ã€‚

**Q: å¦‚ä½•é€‰æ‹©ç¼©æ”¾å› å­ï¼Ÿ**
A: è€ƒè™‘æ•°æ®èŒƒå›´å’Œç²¾åº¦éœ€æ±‚ã€‚å½“å‰è®¾ç½®å¯è¡¨ç¤ºÂ±{2 ** 31 // self.scale_factor}èŒƒå›´çš„æ•°å€¼ã€‚

**Q: å†…å­˜ä¸å¤Ÿæ€ä¹ˆåŠï¼Ÿ**
A: å¯ä»¥å‡å°sigmoidæŸ¥æ‰¾è¡¨å¤§å°ï¼Œæˆ–ä½¿ç”¨æ›´ç®€å•çš„æ¿€æ´»å‡½æ•°ã€‚
"""

            guide_file = os.path.join(self.output_dir, "README_INTEGER.md")
            return self.write_file(guide_file, guide_content)

        except Exception as e:
            print(f"âŒ ä½¿ç”¨è¯´æ˜ç”Ÿæˆå¤±è´¥: {e}")
            return False


class ObstacleHeightClassifier:
    """éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨ - åŸºç¡€ç‰ˆæœ¬"""

    def __init__(self, config=None):
        # é»˜è®¤é…ç½®
        self.config = {
            'model_dir': './models',
            'plot_dir': './plots',
            'results_dir': './results',
            'misclassified_dir': './misclassified',
            'auto_create_dirs': True,
            'encoding': 'utf-8-sig',
            'test_size': 0.3,
            'random_state': 42,
            'save_model': True,
        }

        # æ›´æ–°ç”¨æˆ·é…ç½®
        if config:
            self.config.update(config)

        # æ¨¡å‹ç›¸å…³å±æ€§
        self.model = None
        self.feature_names = []
        self.test_results = {}

        # åˆ›å»ºè¾“å‡ºç›®å½•
        if self.config['auto_create_dirs']:
            self.create_directories()

    def create_directories(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•"""
        dirs = [
            self.config['model_dir'],
            self.config['plot_dir'],
            self.config['results_dir'],
            self.config['misclassified_dir']
        ]
        for dir_path in dirs:
            os.makedirs(dir_path, exist_ok=True)
            print(f"ç¡®ä¿ç›®å½•å­˜åœ¨: {dir_path}")

    def save_csv(self, df, filepath, encoding=None):
        """ä¿å­˜CSVæ–‡ä»¶ï¼Œè§£å†³ä¸­æ–‡ä¹±ç é—®é¢˜"""
        encoding = encoding or self.config['encoding']
        try:
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            df.to_csv(filepath, index=False, encoding=encoding)
            print(f"æ–‡ä»¶å·²ä¿å­˜åˆ°: {filepath}")
            print(f"æ–‡ä»¶å¤§å°: {os.path.getsize(filepath)} bytes")
            return True
        except Exception as e:
            print(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            try:
                df.to_csv(filepath, index=False, encoding='gbk')
                print(f"ä½¿ç”¨GBKç¼–ç ä¿å­˜åˆ°: {filepath}")
                return True
            except Exception as e2:
                try:
                    df.to_csv(filepath, index=False, encoding='utf-8')
                    print(f"ä½¿ç”¨UTF-8ç¼–ç ä¿å­˜åˆ°: {filepath}")
                    return True
                except Exception as e3:
                    print(f"æ‰€æœ‰ç¼–ç å°è¯•å¤±è´¥: {e3}")
                    return False

    def load_data(self, filepath):
        """åŠ è½½æ•°æ®"""
        print(f"åŠ è½½æ•°æ®: {filepath}")
        try:
            df = pd.read_csv(filepath, encoding='utf-8-sig')
        except:
            try:
                df = pd.read_csv(filepath, encoding='gbk')
            except:
                df = pd.read_csv(filepath)

        print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
        if 'HeightLabel' in df.columns:
            print(f"HeightLabelåˆ†å¸ƒ: {df['HeightLabel'].value_counts().to_dict()}")
            print(f"é«˜éšœç¢ç‰©æ¯”ä¾‹: {df['HeightLabel'].mean():.2%}")

        return df

    def feature_engineering(self, df):
        """ç‰¹å¾å·¥ç¨‹"""
        print("è¿›è¡Œç‰¹å¾å·¥ç¨‹...")
        df_processed = df.copy()

        # æ’é™¤æè¿°æ€§å’Œæ— å…³ç‰¹å¾
        exclude_cols = [
            'HeightLabel',
            'Train_OD_Project',
            'ObjName',
            'Direction',
            'Obj_ID',
            'CurCyc',
            'TxSensID',
        ]

        print(f"æ’é™¤çš„ç‰¹å¾åˆ—: {exclude_cols}")

        # è·å–åŸºç¡€ç‰¹å¾åˆ—
        base_features = [col for col in df_processed.columns if col not in exclude_cols]
        print(f"åŸºç¡€ç‰¹å¾åˆ—: {base_features}")

        # åˆ›å»ºæ–°ç‰¹å¾
        feature_ops = {
            'DeEcho_Ratio': lambda x: x['PosDeDis1'] / (x['PosDeDis2'] + 1e-8),
            'CeEcho_Ratio': lambda x: x['PosCeDis1'] / (x['PosCeDis2'] + 1e-8),
            'DeAmp_Ratio': lambda x: x['PosDeAmp1'] / (x['PosDeAmp2'] + 1e-8),
            'CeAmp_Ratio': lambda x: x['PosCeAmp1'] / (x['PosCeAmp2'] + 1e-8),
            'Total_DeEcho': lambda x: x['PosDeDis1'] + x['PosDeDis2'],
            'Total_CeEcho': lambda x: x['PosCeDis1'] + x['PosCeDis2'],
            'Total_DeAmp': lambda x: x['PosDeAmp1'] + x['PosDeAmp2'],
            'Total_CeAmp': lambda x: x['PosCeAmp1'] + x['PosCeAmp2'],
            'DeDis_Diff': lambda x: x['PosDeDis1'] - x['PosDeDis2'],
            'CeDis_Diff': lambda x: x['PosCeDis1'] - x['PosCeDis2'],
            'DeAmp_Diff': lambda x: x['PosDeAmp1'] - x['PosDeAmp2'],
            'CeAmp_Diff': lambda x: x['PosCeAmp1'] - x['PosCeAmp2'],
            'Avg_Echo_Strength': lambda x: (x['AvgDeEchoHigh_SameTx'] + x['AvgCeEchoHigh_SameTxRx']) / 2,
            'Distance_Ratio': lambda x: x['TrainObjDist'] / (x['AngleDist'] + 1e-8),
            'Echo_Strength_Ratio': lambda x: x['AvgDeEchoHigh_SameTx'] / (x['AvgCeEchoHigh_SameTxRx'] + 1e-8),
            'Odo_Stability': lambda x: x['OdoDiffObjDis'] / (x['OdoDiffDeDis'] + 1e-8),
        }

        # åº”ç”¨ç‰¹å¾å·¥ç¨‹
        for feature_name, operation in feature_ops.items():
            try:
                df_processed[feature_name] = operation(df_processed)
                print(f"åˆ›å»ºç‰¹å¾: {feature_name}")
            except Exception as e:
                print(f"ç‰¹å¾ {feature_name} åˆ›å»ºå¤±è´¥: {e}")

        # æ›´æ–°ç‰¹å¾åˆ—è¡¨
        self.feature_names = [col for col in df_processed.columns if col not in exclude_cols]
        print(f"ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œå…± {len(self.feature_names)} ä¸ªç‰¹å¾")

        # ç‰¹å¾è´¨é‡æ£€æŸ¥
        self.check_feature_quality(df_processed)

        return df_processed

    def check_feature_quality(self, df):
        """æ£€æŸ¥ç‰¹å¾è´¨é‡"""
        print("\n=== ç‰¹å¾è´¨é‡æ£€æŸ¥ ===")

        # æ£€æŸ¥ç¼ºå¤±å€¼
        missing_stats = df[self.feature_names].isnull().sum()
        if missing_stats.sum() > 0:
            print("å‘ç°ç¼ºå¤±å€¼:")
            print(missing_stats[missing_stats > 0])
        else:
            print("âœ“ æ— ç¼ºå¤±å€¼")

        # æ£€æŸ¥å¸¸æ•°ç‰¹å¾
        constant_features = []
        for feature in self.feature_names:
            if df[feature].nunique() <= 1:
                constant_features.append(feature)

        if constant_features:
            print(f"å‘ç°å¸¸æ•°ç‰¹å¾: {constant_features}")
            self.feature_names = [f for f in self.feature_names if f not in constant_features]
            print(f"ç§»é™¤å¸¸æ•°ç‰¹å¾åå‰©ä½™: {len(self.feature_names)} ä¸ªç‰¹å¾")
        else:
            print("âœ“ æ— å¸¸æ•°ç‰¹å¾")

        # æ£€æŸ¥æ— ç©·å€¼
        inf_features = []
        for feature in self.feature_names:
            if np.isinf(df[feature]).any():
                inf_features.append(feature)

        if inf_features:
            print(f"å‘ç°æ— ç©·å€¼ç‰¹å¾: {inf_features}")
            for feature in inf_features:
                df[feature] = df[feature].replace([np.inf, -np.inf], np.nan)
                df[feature] = df[feature].fillna(df[feature].median())
            print("å·²æ›¿æ¢æ— ç©·å€¼ä¸ºä¸­ä½æ•°")
        else:
            print("âœ“ æ— æ— ç©·å€¼")

    def train(self, train_df):
        """è®­ç»ƒæ¨¡å‹"""
        print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")

        # å‡†å¤‡æ•°æ®
        X = train_df[self.feature_names]
        y = train_df['HeightLabel']

        print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: X{X.shape}, y{y.shape}")

        # åˆ’åˆ†æ•°æ®é›†
        if self.config['test_size'] > 0:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=self.config['test_size'],
                random_state=self.config['random_state'], stratify=y
            )
            print(f"è®­ç»ƒé›†: {X_train.shape[0]}, æµ‹è¯•é›†: {X_test.shape[0]}")
        else:
            X_train, y_train = X, y
            X_test = y_test = None
            print(f"ä½¿ç”¨å…¨éƒ¨æ•°æ®è®­ç»ƒ: {X_train.shape[0]}")

        # LightGBMå‚æ•°
        params = {
            'objective': 'binary',
            'metric': 'binary_logloss',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.05,
            'feature_fraction': 0.9,
            'bagging_fraction': 0.8,
            'bagging_freq': 5,
            'verbose': -1,
            'random_state': self.config['random_state'],
            'is_unbalance': True,
            'min_child_samples': 20,
            'min_child_weight': 0.001,
            'subsample_for_bin': 200000,
            'reg_alpha': 0.1,
            'reg_lambda': 0.1,
        }

        # è®­ç»ƒ
        train_data = lgb.Dataset(X_train, label=y_train)
        if X_test is not None:
            valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)
            valid_sets = [train_data, valid_data]
            valid_names = ['train', 'valid']
        else:
            valid_sets = [train_data]
            valid_names = ['train']

        self.model = lgb.train(
            params, train_data, valid_sets=valid_sets, valid_names=valid_names,
            num_boost_round=1000, callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]
        )

        # ä¿å­˜æµ‹è¯•ç»“æœ
        if X_test is not None:
            y_pred_proba = self.model.predict(X_test, num_iteration=self.model.best_iteration)
            y_pred = (y_pred_proba > 0.5).astype(int)

            self.test_results = {
                'X_test': X_test, 'y_test': y_test,
                'y_pred': y_pred, 'y_pred_proba': y_pred_proba
            }

            # è¯„ä¼°
            self.evaluate_model()

        # ä¿å­˜æ¨¡å‹
        if self.config['save_model']:
            self.save_model()

        return self.test_results if X_test is not None else None

    def evaluate_model(self):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        if not self.test_results:
            return

        y_test = self.test_results['y_test']
        y_pred = self.test_results['y_pred']
        y_pred_proba = self.test_results['y_pred_proba']

        print("\n=== æ¨¡å‹è¯„ä¼°ç»“æœ ===")
        print(f"å‡†ç¡®ç‡: {accuracy_score(y_test, y_pred):.4f}")
        print(f"AUC: {roc_auc_score(y_test, y_pred_proba):.4f}")
        print("\nåˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_test, y_pred, target_names=['ä½éšœç¢ç‰©', 'é«˜éšœç¢ç‰©']))

        # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        self.plot_confusion_matrix()

    def plot_confusion_matrix(self, title_suffix=""):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        if not self.test_results:
            print("æ— æµ‹è¯•æ•°æ®ï¼Œè·³è¿‡æ··æ·†çŸ©é˜µç»˜åˆ¶")
            return

        y_test = self.test_results['y_test']
        y_pred = self.test_results['y_pred']
        cm = confusion_matrix(y_test, y_pred)

        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['ä½éšœç¢ç‰©', 'é«˜éšœç¢ç‰©'],
                    yticklabels=['ä½éšœç¢ç‰©', 'é«˜éšœç¢ç‰©'])
        plt.title(f'æ··æ·†çŸ©é˜µ{title_suffix}')
        plt.ylabel('çœŸå®æ ‡ç­¾')
        plt.xlabel('é¢„æµ‹æ ‡ç­¾')

        save_path = os.path.join(self.config['plot_dir'], f'confusion_matrix{title_suffix.replace(" ", "_")}.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: {save_path}")
        plt.show()

        return cm

    def plot_feature_importance(self, top_n=20):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§"""
        if self.model is None:
            print("æ¨¡å‹æœªè®­ç»ƒ")
            return

        importance = self.model.feature_importance(importance_type='gain')
        feature_imp = pd.DataFrame({
            'feature': self.feature_names,
            'importance': importance
        }).sort_values('importance', ascending=False)

        plt.figure(figsize=(10, 8))
        sns.barplot(data=feature_imp.head(top_n), x='importance', y='feature')
        plt.title(f'å‰{top_n}ä¸ªé‡è¦ç‰¹å¾')
        plt.xlabel('é‡è¦æ€§')

        save_path = os.path.join(self.config['plot_dir'], f'feature_importance_top{top_n}.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜åˆ°: {save_path}")
        plt.show()

        return feature_imp

    def save_model(self, filepath=None):
        """ä¿å­˜æ¨¡å‹"""
        if self.model is None:
            print("æ¨¡å‹æœªè®­ç»ƒ")
            return None

        if filepath is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filepath = os.path.join(self.config['model_dir'], f'obstacle_classifier_{timestamp}.joblib')

        model_data = {
            'model': self.model,
            'feature_names': self.feature_names,
            'config': self.config,
            'timestamp': datetime.now().isoformat()
        }

        joblib.dump(model_data, filepath)
        print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {filepath}")

        return filepath

    def predict(self, test_filepath, output_filepath=None):
        """é¢„æµ‹æµ‹è¯•æ•°æ®"""
        if self.model is None:
            print("æ¨¡å‹æœªè®­ç»ƒ")
            return None

        print(f"é¢„æµ‹æµ‹è¯•æ•°æ®: {test_filepath}")

        # åŠ è½½æµ‹è¯•æ•°æ®
        test_df = self.load_data(test_filepath)
        test_df_processed = self.feature_engineering(test_df)

        # é¢„æµ‹
        X_test = test_df_processed[self.feature_names]
        y_pred_proba = self.model.predict(X_test, num_iteration=self.model.best_iteration)
        y_pred = (y_pred_proba > 0.5).astype(int)

        # åˆ›å»ºç»“æœ
        results = test_df.copy()

        # æ·»åŠ é¢„æµ‹ç»“æœ
        if 'HeightLabel' in test_df.columns:
            results['True_Label'] = test_df['HeightLabel']

        results['Predicted_HeightLabel'] = y_pred
        results['Prediction_Probability'] = y_pred_proba
        results['Confidence'] = np.abs(y_pred_proba - 0.5) * 2

        if 'HeightLabel' in test_df.columns:
            results['Prediction_Correct'] = (results['True_Label'] == results['Predicted_HeightLabel'])
            results['Error_Type'] = results.apply(
                lambda row: 'Correct' if row['Prediction_Correct'] else
                ('False_Positive' if row['True_Label'] == 0 else 'False_Negative'), axis=1
            )

        # ä¿å­˜ç»“æœ
        if output_filepath is None:
            filename = f"prediction_results_{os.path.splitext(os.path.basename(test_filepath))[0]}.csv"
            output_filepath = os.path.join(self.config['results_dir'], filename)

        self.save_csv(results, output_filepath)

        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\né¢„æµ‹ç»Ÿè®¡:")
        print(f"é¢„æµ‹ä¸ºé«˜éšœç¢ç‰©æ¯”ä¾‹: {y_pred.mean():.2%}")
        print(f"å¹³å‡é¢„æµ‹æ¦‚ç‡: {y_pred_proba.mean():.4f}")

        # å¦‚æœæœ‰çœŸå®æ ‡ç­¾ï¼Œè¿›è¡Œè¯„ä¼°
        if 'HeightLabel' in test_df.columns:
            y_true = test_df['HeightLabel'].values
            accuracy = accuracy_score(y_true, y_pred)
            auc = roc_auc_score(y_true, y_pred_proba)

            print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f}")
            print(f"æµ‹è¯•é›†AUC: {auc:.4f}")

            # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
            test_name = os.path.splitext(os.path.basename(test_filepath))[0]
            self.test_results = {
                'y_test': y_true, 'y_pred': y_pred, 'y_pred_proba': y_pred_proba
            }
            self.plot_confusion_matrix(f"_{test_name}")

        return results

    def load_model(self, filepath):
        """åŠ è½½æ¨¡å‹"""
        try:
            model_data = joblib.load(filepath)
            if isinstance(model_data, dict):
                self.model = model_data['model']
                self.feature_names = model_data['feature_names']
                if 'config' in model_data:
                    self.config.update(model_data['config'])
            else:
                self.model = model_data

            print(f"æ¨¡å‹åŠ è½½æˆåŠŸ: {filepath}")
            print(f"ç‰¹å¾æ•°é‡: {len(self.feature_names)}")
            return True
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False


class ObstacleHeightClassifierWithIntegerConversion(ObstacleHeightClassifier):
    """éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨ - å¢åŠ æ•´å‹è½¬æ¢åŠŸèƒ½"""

    def __init__(self, config=None):
        super().__init__(config)

        # æ·»åŠ æ•´å‹è½¬æ¢ç›¸å…³é…ç½®
        self.config.update({
            'c_model_integer_dir': './c_model_integer',
            'auto_convert_to_c_integer': True,
            'scale_factor': 10000,  # å®šç‚¹æ•°ç¼©æ”¾å› å­
        })

        if config:
            self.config.update(config)

    def convert_to_c_integer(self):
        """å°†è®­ç»ƒå¥½çš„æ¨¡å‹è½¬æ¢ä¸ºCè¯­è¨€æ•´å‹ä»£ç """
        if self.model is None:
            print("âŒ æ¨¡å‹æœªè®­ç»ƒï¼Œæ— æ³•è½¬æ¢")
            return False

        try:
            print(f"ğŸ“ å¼€å§‹è½¬æ¢LightGBMæ¨¡å‹ä¸ºCè¯­è¨€æ•´å‹ä»£ç ...")
            print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯æ£€æŸ¥:")
            print(f"   - æ¨¡å‹ç±»å‹: {type(self.model)}")
            print(f"   - ç‰¹å¾æ•°é‡: {len(self.feature_names)}")
            print(f"   - ç¼©æ”¾å› å­: {self.config['scale_factor']}")
            print(f"   - è¾“å‡ºç›®å½•: {self.config['c_model_integer_dir']}")

            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰å¿…è¦çš„æ–¹æ³•
            if not hasattr(self.model, 'dump_model'):
                print(f"âŒ æ¨¡å‹ä¸æ”¯æŒdump_modelæ–¹æ³•")
                return False

            # æ£€æŸ¥ç‰¹å¾åç§°
            if not self.feature_names:
                print(f"âŒ ç‰¹å¾åç§°åˆ—è¡¨ä¸ºç©º")
                return False

            print(f"âœ… æ¨¡å‹æ£€æŸ¥é€šè¿‡ï¼Œå¼€å§‹è½¬æ¢...")

            # ä½¿ç”¨æ•´å‹è½¬æ¢å™¨
            converter = LightGBMToCIntegerConverter(
                model=self.model,
                feature_names=self.feature_names,
                output_dir=self.config['c_model_integer_dir'],
                scale_factor=self.config['scale_factor']
            )

            # æ‰§è¡Œè½¬æ¢
            success = converter.convert()

            if success:
                print(f"\nğŸ‰ Cè¯­è¨€æ•´å‹è½¬æ¢å®Œæˆ!")
                print(f"ğŸ“ Cè¯­è¨€æ•´å‹ä»£ç ä¿å­˜åœ¨: {self.config['c_model_integer_dir']}")
                print(f"ğŸ”¨ ç¼–è¯‘å‘½ä»¤: cd {self.config['c_model_integer_dir']} && make")
                print(f"ğŸš€ è¿è¡Œæµ‹è¯•: cd {self.config['c_model_integer_dir']} && ./test_obstacle_height_int")

                # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„ç”Ÿæˆäº†
                expected_files = [
                    "obstacle_height_model_int.h",
                    "obstacle_height_model_int.c",
                    "test_obstacle_height_int.c",
                    "Makefile",
                    "data_converter.c"
                ]
                missing_files = []

                for filename in expected_files:
                    filepath = os.path.join(self.config['c_model_integer_dir'], filename)
                    if not os.path.exists(filepath):
                        missing_files.append(filename)

                if missing_files:
                    print(f"âš ï¸  è­¦å‘Š: ä»¥ä¸‹æ–‡ä»¶æœªç”Ÿæˆ: {missing_files}")
                    return False
                else:
                    print(f"âœ… æ‰€æœ‰å¿…è¦æ–‡ä»¶å·²ç”Ÿæˆ")
                    return True
            else:
                print(f"âŒ Cè¯­è¨€æ•´å‹è½¬æ¢å¤±è´¥")
                return False

        except Exception as e:
            print(f"âŒ Cè¯­è¨€æ•´å‹è½¬æ¢å¼‚å¸¸: {e}")
            return False

    def train(self, train_df):
        """è®­ç»ƒæ¨¡å‹å¹¶è‡ªåŠ¨è½¬æ¢ä¸ºæ•´å‹Cä»£ç """
        # è°ƒç”¨çˆ¶ç±»çš„è®­ç»ƒæ–¹æ³•
        result = super().train(train_df)

        # è‡ªåŠ¨è½¬æ¢ä¸ºæ•´å‹Cè¯­è¨€
        if self.config['auto_convert_to_c_integer']:
            print(f"\nğŸ”„ å¼€å§‹è‡ªåŠ¨è½¬æ¢ä¸ºCè¯­è¨€æ•´å‹ä»£ç ...")
            self.convert_to_c_integer()

        return result

    def create_directories(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆåŒ…æ‹¬æ•´å‹ç‰ˆæœ¬ç›®å½•ï¼‰"""
        super().create_directories()
        os.makedirs(self.config['c_model_integer_dir'], exist_ok=True)
        print(f"ç¡®ä¿ç›®å½•å­˜åœ¨: {self.config['c_model_integer_dir']}")


def quick_run_with_integer_conversion(train_file, test_file=None, config=None):
    """å¿«é€Ÿè¿è¡Œå‡½æ•° - å«è‡ªåŠ¨æ•´å‹Cè¯­è¨€è½¬æ¢"""
    print("=== éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨ - æ•´å‹Cè¯­è¨€ç‰ˆæœ¬ ===\n")

    # é»˜è®¤é…ç½®
    default_config = {
        'model_dir': './models_integer',
        'plot_dir': './plots_integer',
        'results_dir': './results_integer',
        'misclassified_dir': './misclassified_integer',
        'c_model_integer_dir': './c_model_integer',
        'auto_convert_to_c_integer': True,
        'scale_factor': 10000,  # å¯ä»¥è°ƒæ•´ç²¾åº¦
        'test_size': 0.0,  # ä½¿ç”¨å…¨éƒ¨æ•°æ®è®­ç»ƒ
        'random_state': 42,
    }

    if config:
        default_config.update(config)

    # åˆ›å»ºåˆ†ç±»å™¨
    classifier = ObstacleHeightClassifierWithIntegerConversion(default_config)

    # è®­ç»ƒ
    print("1. æ•°æ®åŠ è½½å’Œç‰¹å¾å·¥ç¨‹")
    train_df = classifier.load_data(train_file)
    train_df_processed = classifier.feature_engineering(train_df)

    print("\n2. æ¨¡å‹è®­ç»ƒå’Œæ•´å‹è½¬æ¢")
    classifier.train(train_df_processed)

    # ç‰¹å¾é‡è¦æ€§åˆ†æ
    print("\n3. ç‰¹å¾é‡è¦æ€§åˆ†æ")
    classifier.plot_feature_importance()

    # é¢„æµ‹æµ‹è¯•æ•°æ®
    if test_file and os.path.exists(test_file):
        print("\n4. æµ‹è¯•æ•°æ®é¢„æµ‹")
        classifier.predict(test_file)
    else:
        print("\n4. è·³è¿‡é¢„æµ‹é˜¶æ®µï¼ˆæ— æµ‹è¯•æ–‡ä»¶ï¼‰")

    print("\n=== è¿è¡Œå®Œæˆ ===")
    print(f"ğŸ“Š Pythonæ¨¡å‹æ–‡ä»¶: {classifier.config['model_dir']}")
    print(f"ğŸ”§ Cè¯­è¨€æ•´å‹ä»£ç : {classifier.config['c_model_integer_dir']}")

    return classifier


def convert_existing_model_to_c_integer(model_path, output_dir="./c_model_integer_converted", scale_factor=10000):
    """è½¬æ¢å·²ä¿å­˜çš„.joblibæ¨¡å‹æ–‡ä»¶ä¸ºCè¯­è¨€æ•´å‹ä»£ç """
    try:
        # åŠ è½½æ¨¡å‹
        model_data = joblib.load(model_path)
        if isinstance(model_data, dict):
            model = model_data['model']
            feature_names = model_data.get('feature_names', [])
        else:
            model = model_data
            feature_names = []

        print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {model_path}")
        print(f"ğŸ¯ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ”¢ ç¼©æ”¾å› å­: {scale_factor}")

        # åˆ›å»ºè½¬æ¢å™¨å¹¶æ‰§è¡Œè½¬æ¢
        converter = LightGBMToCIntegerConverter(model, feature_names, output_dir, scale_factor)
        success = converter.convert()

        return success

    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    # ==================== é…ç½®åŒºåŸŸ ====================

    # æ–‡ä»¶è·¯å¾„é…ç½®
    TRAIN_FILE = r'D:\PythonProject\data\processed_data\merged_train_data_fixed.csv'
    TEST_FILE = r'D:\PythonProject\data\processed_data\train_group2.csv'

    # è¾“å‡ºè·¯å¾„é…ç½®
    OUTPUT_CONFIG = {
        'model_dir': r'D:\PythonProject\model\saved_model_integer',
        'plot_dir': r'D:\PythonProject\results\visualization_results_integer',
        'results_dir': r'D:\PythonProject\results\prediction_results_integer',
        'misclassified_dir': r'D:\PythonProject\results\misclassified_results_integer',
        'c_model_integer_dir': r'D:\PythonProject\c_model_integer',  # æ•´å‹Cè¯­è¨€æ¨¡å‹è¾“å‡ºç›®å½•
        'auto_create_dirs': True,
        'encoding': 'utf-8-sig',
        'test_size': 0.0,  # ä½¿ç”¨å…¨éƒ¨æ•°æ®è®­ç»ƒ
        'random_state': 42,
        'save_model': True,
        'auto_convert_to_c_integer': True,  # å¯ç”¨è‡ªåŠ¨è½¬æ¢ä¸ºæ•´å‹Cè¯­è¨€
        'scale_factor': 10000,  # å®šç‚¹æ•°ç¼©æ”¾å› å­ï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´
    }

    print(f"ğŸš€ å¼€å§‹è¿è¡Œæ•´å‹Cè¯­è¨€ç‰ˆéšœç¢ç‰©åˆ†ç±»å™¨...")
    print(f"ğŸ“ æ•´å‹Cè¯­è¨€æ¨¡å‹å°†ä¿å­˜åœ¨: {OUTPUT_CONFIG['c_model_integer_dir']}")
    print(f"ğŸ”¢ ç¼©æ”¾å› å­: {OUTPUT_CONFIG['scale_factor']} (ç²¾åº¦: {1.0 / OUTPUT_CONFIG['scale_factor']})")
    print(f"{'=' * 80}")

    try:
        # æ£€æŸ¥è®­ç»ƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(TRAIN_FILE):
            print(f"âŒ è®­ç»ƒæ–‡ä»¶ä¸å­˜åœ¨: {TRAIN_FILE}")
            print(f"è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
            exit(1)

        # è¿è¡Œåˆ†ç±»å™¨
        classifier = quick_run_with_integer_conversion(TRAIN_FILE, TEST_FILE, OUTPUT_CONFIG)

        print(f"\n{'=' * 80}")
        print(f"âœ… è®­ç»ƒå’Œæ•´å‹è½¬æ¢å®Œæˆï¼")
        print(f"\nğŸ“Š Pythonæ¨¡å‹å’Œç»“æœ:")
        print(f"   - æ¨¡å‹æ–‡ä»¶: {OUTPUT_CONFIG['model_dir']}")
        print(f"   - å¯è§†åŒ–ç»“æœ: {OUTPUT_CONFIG['plot_dir']}")
        print(f"   - é¢„æµ‹ç»“æœ: {OUTPUT_CONFIG['results_dir']}")

        print(f"\nğŸ”§ Cè¯­è¨€æ•´å‹æ¨¡å‹:")
        print(f"   - Cä»£ç ç›®å½•: {OUTPUT_CONFIG['c_model_integer_dir']}")
        print(f"   - ç¼–è¯‘å‘½ä»¤: cd {OUTPUT_CONFIG['c_model_integer_dir']} && make")
        print(f"   - è¿è¡Œæµ‹è¯•: cd {OUTPUT_CONFIG['c_model_integer_dir']} && ./test_obstacle_height_int")

        # éªŒè¯Cè¯­è¨€æ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
        c_files = [
            'obstacle_height_model_int.h',
            'obstacle_height_model_int.c',
            'test_obstacle_height_int.c',
            'Makefile',
            'data_converter.c'
        ]
        missing_files = []

        for filename in c_files:
            filepath = os.path.join(OUTPUT_CONFIG['c_model_integer_dir'], filename)
            if not os.path.exists(filepath):
                missing_files.append(filename)
            else:
                size = os.path.getsize(filepath)
                print(f"   âœ… {filename} ({size} bytes)")

        if missing_files:
            print(f"\nâš ï¸  è­¦å‘Š: ä»¥ä¸‹Cè¯­è¨€æ–‡ä»¶æœªç”Ÿæˆ: {missing_files}")
        else:
            print(f"\nğŸ‰ æ‰€æœ‰Cè¯­è¨€æ•´å‹æ–‡ä»¶å·²æˆåŠŸç”Ÿæˆ!")
            print(f"\nğŸ“ æ•´å‹ç‰ˆæœ¬ç‰¹ç‚¹:")
            print(f"   - ä½¿ç”¨ int32_t æ•°æ®ç±»å‹")
            print(f"   - ç¼©æ”¾å› å­: {OUTPUT_CONFIG['scale_factor']}")
            print(f"   - æ•°å€¼ç²¾åº¦: {1.0 / OUTPUT_CONFIG['scale_factor']}")
            print(f"   - é€‚åˆæ— FPUçš„MCU")
            print(f"   - æŸ¥æ‰¾è¡¨å®ç°sigmoidå‡½æ•°")

            print(f"\nğŸ“ ä¸‹ä¸€æ­¥:")
            print(f"   1. è¿›å…¥Cæ¨¡å‹ç›®å½•: cd {OUTPUT_CONFIG['c_model_integer_dir']}")
            print(f"   2. ç¼–è¯‘é¡¹ç›®: make")
            print(f"   3. è¿è¡Œæµ‹è¯•: ./test_obstacle_height_int")
            print(f"   4. æŸ¥çœ‹README_INTEGER.mdäº†è§£è¯¦ç»†ä½¿ç”¨æ–¹æ³•")

    except FileNotFoundError as e:
        print(f"\nâŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        print(f"ğŸ”§ è¯·æ£€æŸ¥:")
        print(f"   1. è®­ç»ƒæ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {TRAIN_FILE}")
        print(f"   2. æµ‹è¯•æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {TEST_FILE}")

    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        print(f"\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print(f"   1. æ£€æŸ¥Pythonç¯å¢ƒå’Œä¾èµ–åŒ…")
        print(f"   2. æ£€æŸ¥æ•°æ®æ–‡ä»¶æ ¼å¼å’Œå†…å®¹")
        print(f"   3. æ£€æŸ¥è¾“å‡ºç›®å½•æƒé™")
        print(f"   4. å°è¯•è°ƒæ•´ç¼©æ”¾å› å­scale_factor")

    print(f"\nğŸ ç¨‹åºç»“æŸ")