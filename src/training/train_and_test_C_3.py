#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨ - å®Œå…¨æ¸…ç†ç‰ˆæœ¬
åŒ…å«LightGBMæ¨¡å‹è®­ç»ƒå’Œè‡ªåŠ¨Cè¯­è¨€è½¬æ¢åŠŸèƒ½
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import joblib
import os
import json
from datetime import datetime

warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibæ”¯æŒä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class LightGBMToCConverter:
    """LightGBMæ¨¡å‹è½¬Cè¯­è¨€ä»£ç ç”Ÿæˆå™¨"""

    def __init__(self, model, feature_names, output_dir="./c_model"):
        """åˆå§‹åŒ–è½¬æ¢å™¨"""
        print(f"ğŸ” åˆå§‹åŒ–Cè¯­è¨€è½¬æ¢å™¨...")
        print(f"   - æ¨¡å‹ç±»å‹: {type(model)}")
        print(f"   - ç‰¹å¾æ•°é‡: {len(feature_names)}")
        print(f"   - è¾“å‡ºç›®å½•: {output_dir}")

        self.model = model
        self.feature_names = feature_names
        self.output_dir = output_dir
        self.num_features = len(feature_names)
        self.num_trees = 0
        self.trees = []
        self.objective = 'binary'

        # åˆ›å»ºè¾“å‡ºç›®å½•
        try:
            os.makedirs(output_dir, exist_ok=True)
            print(f"âœ… è¾“å‡ºç›®å½•åˆ›å»ºæˆåŠŸ: {output_dir}")
        except Exception as e:
            print(f"âŒ è¾“å‡ºç›®å½•åˆ›å»ºå¤±è´¥: {e}")
            raise

    def extract_model_info(self):
        """æå–æ¨¡å‹ä¿¡æ¯"""
        print(f"ğŸ” æå–æ¨¡å‹ä¿¡æ¯...")

        try:
            if not hasattr(self.model, 'dump_model'):
                raise ValueError(f"æ¨¡å‹ç±»å‹ {type(self.model)} ä¸æ”¯æŒdump_modelæ–¹æ³•")

            model_dict = self.model.dump_model()
            print(f"âœ… æ¨¡å‹ä¿¡æ¯æå–æˆåŠŸ")

            self.num_trees = model_dict.get('num_tree_per_iteration', 1)
            self.trees = model_dict.get('tree_info', [])
            self.objective = model_dict.get('objective', 'binary')

            print(f"ğŸ“Š æ¨¡å‹è¯¦ç»†ä¿¡æ¯:")
            print(f"   - æ ‘çš„æ•°é‡: {len(self.trees)}")
            print(f"   - æ¯æ¬¡è¿­ä»£æ ‘æ•°: {self.num_trees}")
            print(f"   - ç‰¹å¾æ•°é‡: {self.num_features}")
            print(f"   - ç›®æ ‡å‡½æ•°: {self.objective}")

            return model_dict

        except Exception as e:
            print(f"âŒ æ¨¡å‹ä¿¡æ¯æå–å¤±è´¥: {e}")
            raise

    def generate_tree_function(self, tree_dict, tree_id):
        """ç”Ÿæˆå•ä¸ªæ ‘çš„Cå‡½æ•°"""
        print(f"ğŸŒ³ ç”Ÿæˆç¬¬ {tree_id} æ£µæ ‘...")

        try:
            def generate_node_code(node, indent=0):
                """é€’å½’ç”ŸæˆèŠ‚ç‚¹ä»£ç """
                spaces = "    " * indent

                if 'leaf_value' in node:
                    leaf_value = node['leaf_value']
                    return f"{spaces}return {leaf_value:.8f};\n"
                else:
                    feature_idx = node['split_feature']
                    threshold = node['threshold']
                    left_child = node['left_child']
                    right_child = node['right_child']

                    if feature_idx >= self.num_features:
                        raise ValueError(f"ç‰¹å¾ç´¢å¼• {feature_idx} è¶…å‡ºèŒƒå›´ [0, {self.num_features - 1}]")

                    code = f"{spaces}if (features[{feature_idx}] <= {threshold:.8f}) {{\n"
                    code += generate_node_code(left_child, indent + 1)
                    code += f"{spaces}}} else {{\n"
                    code += generate_node_code(right_child, indent + 1)
                    code += f"{spaces}}}\n"

                    return code

            if 'tree_structure' not in tree_dict:
                raise ValueError(f"æ ‘ {tree_id} ç¼ºå°‘ tree_structure")

            tree_structure = tree_dict['tree_structure']

            func_code = f"""
static double tree_{tree_id}(const double *features) {{
{generate_node_code(tree_structure, 1)}}}
"""
            print(f"âœ… ç¬¬ {tree_id} æ£µæ ‘ç”ŸæˆæˆåŠŸ")
            return func_code

        except Exception as e:
            print(f"âŒ ç¬¬ {tree_id} æ£µæ ‘ç”Ÿæˆå¤±è´¥: {e}")
            raise

    def generate_prediction_function(self):
        """ç”Ÿæˆé¢„æµ‹å‡½æ•°"""
        print(f"ğŸ”® ç”Ÿæˆé¢„æµ‹å‡½æ•°...")

        try:
            tree_calls = []
            for i in range(len(self.trees)):
                tree_calls.append(f"    sum += tree_{i}(features);")

            tree_calls_str = "\n".join(tree_calls)

            prediction_code = f"""
double predict_raw(const double *features) {{
    double sum = 0.0;
{tree_calls_str}
    return sum;
}}

double predict_probability(const double *features) {{
    double raw_score = predict_raw(features);
    return 1.0 / (1.0 + exp(-raw_score));
}}

int predict_class(const double *features) {{
    return predict_probability(features) > 0.5 ? 1 : 0;
}}

double predict_confidence(const double *features) {{
    double prob = predict_probability(features);
    return prob > 0.5 ? prob : (1.0 - prob);
}}
"""
            print(f"âœ… é¢„æµ‹å‡½æ•°ç”ŸæˆæˆåŠŸ")
            return prediction_code

        except Exception as e:
            print(f"âŒ é¢„æµ‹å‡½æ•°ç”Ÿæˆå¤±è´¥: {e}")
            raise

    def write_file(self, filepath, content):
        """å†™å…¥æ–‡ä»¶"""
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)

            if os.path.exists(filepath):
                file_size = os.path.getsize(filepath)
                print(f"âœ… æ–‡ä»¶å†™å…¥æˆåŠŸ: {os.path.basename(filepath)} ({file_size} bytes)")
                return True
            else:
                print(f"âŒ æ–‡ä»¶å†™å…¥å¤±è´¥: {os.path.basename(filepath)} (æ–‡ä»¶ä¸å­˜åœ¨)")
                return False

        except Exception as e:
            print(f"âŒ æ–‡ä»¶å†™å…¥å¤±è´¥: {os.path.basename(filepath)}")
            print(f"   é”™è¯¯: {e}")
            return False

    def convert(self):
        """æ‰§è¡Œè½¬æ¢"""
        print(f"\nğŸš€ å¼€å§‹è½¬æ¢LightGBMæ¨¡å‹åˆ°Cè¯­è¨€...")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"{'=' * 60}")

        try:
            # æ£€æŸ¥è¾“å‡ºç›®å½•æƒé™
            if not os.path.exists(self.output_dir):
                print(f"âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {self.output_dir}")
                return False

            if not os.access(self.output_dir, os.W_OK):
                print(f"âŒ è¾“å‡ºç›®å½•æ— å†™å…¥æƒé™: {self.output_dir}")
                return False

            print(f"âœ… è¾“å‡ºç›®å½•æ£€æŸ¥é€šè¿‡")

            # æå–æ¨¡å‹ä¿¡æ¯
            self.extract_model_info()

            # ç”Ÿæˆå¤´æ–‡ä»¶
            print(f"\n1ï¸âƒ£ ç”Ÿæˆå¤´æ–‡ä»¶...")
            header_content = self.generate_header_file()
            header_file = os.path.join(self.output_dir, "obstacle_height_model.h")
            if not self.write_file(header_file, header_content):
                return False

            # ç”Ÿæˆæºæ–‡ä»¶
            print(f"\n2ï¸âƒ£ ç”Ÿæˆæºæ–‡ä»¶...")
            source_content = self.generate_source_file()
            source_file = os.path.join(self.output_dir, "obstacle_height_model.c")
            if not self.write_file(source_file, source_content):
                return False

            # ç”Ÿæˆæµ‹è¯•æ–‡ä»¶
            print(f"\n3ï¸âƒ£ ç”Ÿæˆæµ‹è¯•æ–‡ä»¶...")
            test_content = self.generate_test_file()
            test_file = os.path.join(self.output_dir, "test_obstacle_height.c")
            if not self.write_file(test_file, test_content):
                return False

            # ç”ŸæˆMakefile
            print(f"\n4ï¸âƒ£ ç”ŸæˆMakefile...")
            makefile_content = self.generate_makefile()
            makefile_file = os.path.join(self.output_dir, "Makefile")
            if not self.write_file(makefile_file, makefile_content):
                return False

            # ä¿å­˜ç‰¹å¾æ˜ å°„
            print(f"\n5ï¸âƒ£ ä¿å­˜ç‰¹å¾æ˜ å°„...")
            if not self.save_feature_mapping():
                return False

            # ç”Ÿæˆä½¿ç”¨è¯´æ˜
            print(f"\n6ï¸âƒ£ ç”Ÿæˆä½¿ç”¨è¯´æ˜...")
            if not self.generate_usage_guide():
                return False

            print(f"\nğŸ‰ è½¬æ¢å®Œæˆ!")
            return True

        except Exception as e:
            print(f"\nâŒ è½¬æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def generate_header_file(self):
        """ç”Ÿæˆå¤´æ–‡ä»¶"""
        header_content = f"""#ifndef OBSTACLE_HEIGHT_MODEL_H
#define OBSTACLE_HEIGHT_MODEL_H

#include <math.h>

// æ¨¡å‹ä¿¡æ¯
#define NUM_FEATURES {self.num_features}
#define NUM_TREES {len(self.trees)}

// ç‰¹å¾ç´¢å¼•å®šä¹‰
"""
        for i, feature_name in enumerate(self.feature_names):
            feature_macro = (feature_name.upper()
                             .replace(' ', '_')
                             .replace('-', '_')
                             .replace('(', '')
                             .replace(')', '')
                             .replace('.', '_')
                             .replace('/', '_'))
            header_content += f"#define FEATURE_{feature_macro} {i}\n"

        header_content += f"""
// å‡½æ•°å£°æ˜
double predict_raw(const double *features);
double predict_probability(const double *features);
int predict_class(const double *features);
double predict_confidence(const double *features);

// é¢„æµ‹ç»“æœç»“æ„ä½“
typedef struct {{
    int height_label;
    double probability;
    double confidence;
    double raw_score;
}} ObstacleHeightPrediction;

ObstacleHeightPrediction predict_obstacle_height(const double *features);

#endif // OBSTACLE_HEIGHT_MODEL_H
"""
        return header_content

    def generate_source_file(self):
        """ç”Ÿæˆæºæ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        source_content = f"""/*
 * éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨ - LightGBMæ¨¡å‹Cè¯­è¨€å®ç°
 * ç”Ÿæˆæ—¶é—´: {timestamp}
 * ç‰¹å¾æ•°é‡: {self.num_features}
 * æ ‘çš„æ•°é‡: {len(self.trees)}
 */

#include "obstacle_height_model.h"
#include <math.h>

"""

        # ç”Ÿæˆæ‰€æœ‰æ ‘çš„å‡½æ•°
        print(f"ğŸŒ³ å¼€å§‹ç”Ÿæˆ {len(self.trees)} æ£µæ ‘...")
        for i, tree in enumerate(self.trees):
            tree_func = self.generate_tree_function(tree, i)
            source_content += tree_func

        # ç”Ÿæˆé¢„æµ‹å‡½æ•°
        prediction_func = self.generate_prediction_function()
        source_content += prediction_func

        # ç”Ÿæˆä¾¿åˆ©å‡½æ•°
        source_content += """
ObstacleHeightPrediction predict_obstacle_height(const double *features) {
    ObstacleHeightPrediction result;
    result.raw_score = predict_raw(features);
    result.probability = predict_probability(features);
    result.height_label = predict_class(features);
    result.confidence = predict_confidence(features);
    return result;
}
"""

        return source_content

    def generate_test_file(self):
        """ç”Ÿæˆæµ‹è¯•æ–‡ä»¶"""
        test_content = f"""/*
 * éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨æµ‹è¯•ç¨‹åº
 */

#include <stdio.h>
#include <stdlib.h>
#include "obstacle_height_model.h"

int main() {{
    printf("=== éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨ Cè¯­è¨€ç‰ˆæœ¬ ===\\n");
    printf("ç‰¹å¾æ•°é‡: %d\\n", NUM_FEATURES);
    printf("æ ‘çš„æ•°é‡: %d\\n", NUM_TREES);
    printf("\\n");

    // ç¤ºä¾‹æµ‹è¯•
    double features[NUM_FEATURES] = {{0}};

    // è®¾ç½®ä¸€äº›ç¤ºä¾‹å€¼
    for(int i = 0; i < NUM_FEATURES && i < 10; i++) {{
        features[i] = (double)(i * 100 + 200);
    }}

    ObstacleHeightPrediction result = predict_obstacle_height(features);

    printf("é¢„æµ‹ç»“æœ:\\n");
    printf("- é«˜åº¦æ ‡ç­¾: %d (%s)\\n", result.height_label, 
           result.height_label ? "é«˜éšœç¢ç‰©" : "ä½éšœç¢ç‰©");
    printf("- æ¦‚ç‡: %.6f\\n", result.probability);
    printf("- ç½®ä¿¡åº¦: %.6f\\n", result.confidence);
    printf("- åŸå§‹åˆ†æ•°: %.6f\\n", result.raw_score);

    return 0;
}}
"""
        return test_content

    def generate_makefile(self):
        """ç”ŸæˆMakefile"""
        return """# éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨ Makefile

CC = gcc
CFLAGS = -Wall -O2 -std=c99
LDFLAGS = -lm

TARGET = test_obstacle_height
SOURCES = obstacle_height_model.c test_obstacle_height.c
HEADERS = obstacle_height_model.h

all: $(TARGET)

$(TARGET): $(SOURCES) $(HEADERS)
	$(CC) $(CFLAGS) -o $(TARGET) $(SOURCES) $(LDFLAGS)

clean:
	rm -f $(TARGET)

.PHONY: all clean
"""

    def save_feature_mapping(self):
        """ä¿å­˜ç‰¹å¾æ˜ å°„"""
        try:
            feature_mapping = {
                "feature_names": self.feature_names,
                "feature_count": self.num_features,
                "model_info": {
                    "trees": len(self.trees),
                    "objective": self.objective
                }
            }

            mapping_file = os.path.join(self.output_dir, "feature_mapping.json")
            return self.write_file(mapping_file, json.dumps(feature_mapping, indent=2, ensure_ascii=False))

        except Exception as e:
            print(f"âŒ ç‰¹å¾æ˜ å°„ä¿å­˜å¤±è´¥: {e}")
            return False

    def generate_usage_guide(self):
        """ç”Ÿæˆä½¿ç”¨è¯´æ˜"""
        try:
            guide_content = f"""# éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨ Cè¯­è¨€ç‰ˆæœ¬

## ç¼–è¯‘å’Œè¿è¡Œ
```bash
make
./test_obstacle_height
```

## åœ¨ä½ çš„é¡¹ç›®ä¸­ä½¿ç”¨
```c
#include "obstacle_height_model.h"

double features[NUM_FEATURES];
// è®¾ç½®ç‰¹å¾å€¼...

ObstacleHeightPrediction result = predict_obstacle_height(features);
if (result.height_label == 1) {{
    printf("é«˜éšœç¢ç‰©æ£€æµ‹ï¼\\n");
}}
```

## ç‰¹å¾åˆ—è¡¨ ({self.num_features}ä¸ªç‰¹å¾)
"""
            for i, name in enumerate(self.feature_names):
                guide_content += f"{i}: {name}\n"

            guide_file = os.path.join(self.output_dir, "README.md")
            return self.write_file(guide_file, guide_content)

        except Exception as e:
            print(f"âŒ ä½¿ç”¨è¯´æ˜ç”Ÿæˆå¤±è´¥: {e}")
            return False


class ObstacleHeightClassifier:
    """éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨ - æ¸…ç†ç‰ˆæœ¬"""

    def __init__(self, config=None):
        # é»˜è®¤é…ç½®
        self.config = {
            'model_dir': './models',
            'plot_dir': './plots',
            'results_dir': './results',
            'misclassified_dir': './misclassified',
            'c_model_dir': './c_model',
            'auto_create_dirs': True,
            'encoding': 'utf-8-sig',
            'test_size': 0.3,
            'random_state': 42,
            'save_model': True,
            'auto_convert_to_c': True,
        }

        # æ›´æ–°ç”¨æˆ·é…ç½®
        if config:
            self.config.update(config)

        # æ¨¡å‹ç›¸å…³å±æ€§
        self.model = None
        self.feature_names = []
        self.test_results = {}

        # åˆ›å»ºè¾“å‡ºç›®å½•
        if self.config['auto_create_dirs']:
            self.create_directories()

    def create_directories(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•"""
        dirs = [
            self.config['model_dir'],
            self.config['plot_dir'],
            self.config['results_dir'],
            self.config['misclassified_dir'],
            self.config['c_model_dir']
        ]
        for dir_path in dirs:
            os.makedirs(dir_path, exist_ok=True)
            print(f"ç¡®ä¿ç›®å½•å­˜åœ¨: {dir_path}")

    def save_csv(self, df, filepath, encoding=None):
        """ä¿å­˜CSVæ–‡ä»¶ï¼Œè§£å†³ä¸­æ–‡ä¹±ç é—®é¢˜"""
        encoding = encoding or self.config['encoding']
        try:
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            df.to_csv(filepath, index=False, encoding=encoding)
            print(f"æ–‡ä»¶å·²ä¿å­˜åˆ°: {filepath}")
            print(f"æ–‡ä»¶å¤§å°: {os.path.getsize(filepath)} bytes")
            return True
        except Exception as e:
            print(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            try:
                df.to_csv(filepath, index=False, encoding='gbk')
                print(f"ä½¿ç”¨GBKç¼–ç ä¿å­˜åˆ°: {filepath}")
                return True
            except Exception as e2:
                try:
                    df.to_csv(filepath, index=False, encoding='utf-8')
                    print(f"ä½¿ç”¨UTF-8ç¼–ç ä¿å­˜åˆ°: {filepath}")
                    return True
                except Exception as e3:
                    print(f"æ‰€æœ‰ç¼–ç å°è¯•å¤±è´¥: {e3}")
                    return False

    def load_data(self, filepath):
        """åŠ è½½æ•°æ®"""
        print(f"åŠ è½½æ•°æ®: {filepath}")
        try:
            df = pd.read_csv(filepath, encoding='utf-8-sig')
        except:
            try:
                df = pd.read_csv(filepath, encoding='gbk')
            except:
                df = pd.read_csv(filepath)

        print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
        if 'HeightLabel' in df.columns:
            print(f"HeightLabelåˆ†å¸ƒ: {df['HeightLabel'].value_counts().to_dict()}")
            print(f"é«˜éšœç¢ç‰©æ¯”ä¾‹: {df['HeightLabel'].mean():.2%}")

        return df

    def feature_engineering(self, df):
        """ç‰¹å¾å·¥ç¨‹"""
        print("è¿›è¡Œç‰¹å¾å·¥ç¨‹...")
        df_processed = df.copy()

        # æ’é™¤æè¿°æ€§å’Œæ— å…³ç‰¹å¾
        exclude_cols = [
            'HeightLabel',
            'Train_OD_Project',
            'ObjName',
            'Direction',
            'Obj_ID',
            'CurCyc',
            'TxSensID',
        ]

        print(f"æ’é™¤çš„ç‰¹å¾åˆ—: {exclude_cols}")

        # è·å–åŸºç¡€ç‰¹å¾åˆ—
        base_features = [col for col in df_processed.columns if col not in exclude_cols]
        print(f"åŸºç¡€ç‰¹å¾åˆ—: {base_features}")

        # åˆ›å»ºæ–°ç‰¹å¾
        feature_ops = {
            'DeEcho_Ratio': lambda x: x['PosDeDis1'] / (x['PosDeDis2'] + 1e-8),
            'CeEcho_Ratio': lambda x: x['PosCeDis1'] / (x['PosCeDis2'] + 1e-8),
            'DeAmp_Ratio': lambda x: x['PosDeAmp1'] / (x['PosDeAmp2'] + 1e-8),
            'CeAmp_Ratio': lambda x: x['PosCeAmp1'] / (x['PosCeAmp2'] + 1e-8),
            'Total_DeEcho': lambda x: x['PosDeDis1'] + x['PosDeDis2'],
            'Total_CeEcho': lambda x: x['PosCeDis1'] + x['PosCeDis2'],
            'Total_DeAmp': lambda x: x['PosDeAmp1'] + x['PosDeAmp2'],
            'Total_CeAmp': lambda x: x['PosCeAmp1'] + x['PosCeAmp2'],
            'DeDis_Diff': lambda x: x['PosDeDis1'] - x['PosDeDis2'],
            'CeDis_Diff': lambda x: x['PosCeDis1'] - x['PosCeDis2'],
            'DeAmp_Diff': lambda x: x['PosDeAmp1'] - x['PosDeAmp2'],
            'CeAmp_Diff': lambda x: x['PosCeAmp1'] - x['PosCeAmp2'],
            'Avg_Echo_Strength': lambda x: (x['AvgDeEchoHigh_SameTx'] + x['AvgCeEchoHigh_SameTxRx']) / 2,
            'Distance_Ratio': lambda x: x['TrainObjDist'] / (x['AngleDist'] + 1e-8),
            'Echo_Strength_Ratio': lambda x: x['AvgDeEchoHigh_SameTx'] / (x['AvgCeEchoHigh_SameTxRx'] + 1e-8),
            'Odo_Stability': lambda x: x['OdoDiffObjDis'] / (x['OdoDiffDeDis'] + 1e-8),
        }

        # åº”ç”¨ç‰¹å¾å·¥ç¨‹
        for feature_name, operation in feature_ops.items():
            try:
                df_processed[feature_name] = operation(df_processed)
                print(f"åˆ›å»ºç‰¹å¾: {feature_name}")
            except Exception as e:
                print(f"ç‰¹å¾ {feature_name} åˆ›å»ºå¤±è´¥: {e}")

        # æ›´æ–°ç‰¹å¾åˆ—è¡¨
        self.feature_names = [col for col in df_processed.columns if col not in exclude_cols]
        print(f"ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œå…± {len(self.feature_names)} ä¸ªç‰¹å¾")

        # ç‰¹å¾è´¨é‡æ£€æŸ¥
        self.check_feature_quality(df_processed)

        return df_processed

    def check_feature_quality(self, df):
        """æ£€æŸ¥ç‰¹å¾è´¨é‡"""
        print("\n=== ç‰¹å¾è´¨é‡æ£€æŸ¥ ===")

        # æ£€æŸ¥ç¼ºå¤±å€¼
        missing_stats = df[self.feature_names].isnull().sum()
        if missing_stats.sum() > 0:
            print("å‘ç°ç¼ºå¤±å€¼:")
            print(missing_stats[missing_stats > 0])
        else:
            print("âœ“ æ— ç¼ºå¤±å€¼")

        # æ£€æŸ¥å¸¸æ•°ç‰¹å¾
        constant_features = []
        for feature in self.feature_names:
            if df[feature].nunique() <= 1:
                constant_features.append(feature)

        if constant_features:
            print(f"å‘ç°å¸¸æ•°ç‰¹å¾: {constant_features}")
            self.feature_names = [f for f in self.feature_names if f not in constant_features]
            print(f"ç§»é™¤å¸¸æ•°ç‰¹å¾åå‰©ä½™: {len(self.feature_names)} ä¸ªç‰¹å¾")
        else:
            print("âœ“ æ— å¸¸æ•°ç‰¹å¾")

        # æ£€æŸ¥æ— ç©·å€¼
        inf_features = []
        for feature in self.feature_names:
            if np.isinf(df[feature]).any():
                inf_features.append(feature)

        if inf_features:
            print(f"å‘ç°æ— ç©·å€¼ç‰¹å¾: {inf_features}")
            for feature in inf_features:
                df[feature] = df[feature].replace([np.inf, -np.inf], np.nan)
                df[feature] = df[feature].fillna(df[feature].median())
            print("å·²æ›¿æ¢æ— ç©·å€¼ä¸ºä¸­ä½æ•°")
        else:
            print("âœ“ æ— æ— ç©·å€¼")

    def train(self, train_df):
        """è®­ç»ƒæ¨¡å‹"""
        print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")

        # å‡†å¤‡æ•°æ®
        X = train_df[self.feature_names]
        y = train_df['HeightLabel']

        print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: X{X.shape}, y{y.shape}")

        # åˆ’åˆ†æ•°æ®é›†
        if self.config['test_size'] > 0:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=self.config['test_size'],
                random_state=self.config['random_state'], stratify=y
            )
            print(f"è®­ç»ƒé›†: {X_train.shape[0]}, æµ‹è¯•é›†: {X_test.shape[0]}")
        else:
            X_train, y_train = X, y
            X_test = y_test = None
            print(f"ä½¿ç”¨å…¨éƒ¨æ•°æ®è®­ç»ƒ: {X_train.shape[0]}")

        # LightGBMå‚æ•°
        params = {
            'objective': 'binary',
            'metric': 'binary_logloss',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.05,
            'feature_fraction': 0.9,
            'bagging_fraction': 0.8,
            'bagging_freq': 5,
            'verbose': -1,
            'random_state': self.config['random_state'],
            'is_unbalance': True,
            'min_child_samples': 20,
            'min_child_weight': 0.001,
            'subsample_for_bin': 200000,
            'reg_alpha': 0.1,
            'reg_lambda': 0.1,
        }

        # è®­ç»ƒ
        train_data = lgb.Dataset(X_train, label=y_train)
        if X_test is not None:
            valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)
            valid_sets = [train_data, valid_data]
            valid_names = ['train', 'valid']
        else:
            valid_sets = [train_data]
            valid_names = ['train']

        self.model = lgb.train(
            params, train_data, valid_sets=valid_sets, valid_names=valid_names,
            num_boost_round=1000, callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]
        )

        # ä¿å­˜æµ‹è¯•ç»“æœ
        if X_test is not None:
            y_pred_proba = self.model.predict(X_test, num_iteration=self.model.best_iteration)
            y_pred = (y_pred_proba > 0.5).astype(int)

            self.test_results = {
                'X_test': X_test, 'y_test': y_test,
                'y_pred': y_pred, 'y_pred_proba': y_pred_proba
            }

            # è¯„ä¼°
            self.evaluate_model()

        # ä¿å­˜æ¨¡å‹
        if self.config['save_model']:
            self.save_model()

            # è‡ªåŠ¨è½¬æ¢ä¸ºCè¯­è¨€
            if self.config['auto_convert_to_c']:
                print(f"\nğŸ”„ å¼€å§‹è‡ªåŠ¨è½¬æ¢ä¸ºCè¯­è¨€...")
                self.convert_to_c_language()

        return self.test_results if X_test is not None else None

    def convert_to_c_language(self):
        """å°†è®­ç»ƒå¥½çš„æ¨¡å‹è½¬æ¢ä¸ºCè¯­è¨€ä»£ç """
        if self.model is None:
            print("âŒ æ¨¡å‹æœªè®­ç»ƒï¼Œæ— æ³•è½¬æ¢")
            return False

        try:
            print(f"ğŸ“ å¼€å§‹è½¬æ¢LightGBMæ¨¡å‹ä¸ºCè¯­è¨€ä»£ç ...")
            print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯æ£€æŸ¥:")
            print(f"   - æ¨¡å‹ç±»å‹: {type(self.model)}")
            print(f"   - ç‰¹å¾æ•°é‡: {len(self.feature_names)}")
            print(f"   - è¾“å‡ºç›®å½•: {self.config['c_model_dir']}")

            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰å¿…è¦çš„æ–¹æ³•
            if not hasattr(self.model, 'dump_model'):
                print(f"âŒ æ¨¡å‹ä¸æ”¯æŒdump_modelæ–¹æ³•")
                return False

            # æ£€æŸ¥ç‰¹å¾åç§°
            if not self.feature_names:
                print(f"âŒ ç‰¹å¾åç§°åˆ—è¡¨ä¸ºç©º")
                return False

            print(f"âœ… æ¨¡å‹æ£€æŸ¥é€šè¿‡ï¼Œå¼€å§‹è½¬æ¢...")

            # ä½¿ç”¨è½¬æ¢å™¨
            converter = LightGBMToCConverter(
                model=self.model,
                feature_names=self.feature_names,
                output_dir=self.config['c_model_dir']
            )

            # æ‰§è¡Œè½¬æ¢
            success = converter.convert()

            if success:
                print(f"\nğŸ‰ Cè¯­è¨€è½¬æ¢å®Œæˆ!")
                print(f"ğŸ“ Cè¯­è¨€ä»£ç ä¿å­˜åœ¨: {self.config['c_model_dir']}")
                print(f"ğŸ”¨ ç¼–è¯‘å‘½ä»¤: cd {self.config['c_model_dir']} && make")
                print(f"ğŸš€ è¿è¡Œæµ‹è¯•: cd {self.config['c_model_dir']} && ./test_obstacle_height")

                # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„ç”Ÿæˆäº†
                expected_files = ["obstacle_height_model.h", "obstacle_height_model.c", "test_obstacle_height.c",
                                  "Makefile"]
                missing_files = []

                for filename in expected_files:
                    filepath = os.path.join(self.config['c_model_dir'], filename)
                    if not os.path.exists(filepath):
                        missing_files.append(filename)

                if missing_files:
                    print(f"âš ï¸  è­¦å‘Š: ä»¥ä¸‹æ–‡ä»¶æœªç”Ÿæˆ: {missing_files}")
                    return False
                else:
                    print(f"âœ… æ‰€æœ‰å¿…è¦æ–‡ä»¶å·²ç”Ÿæˆ")
                    return True
            else:
                print(f"âŒ Cè¯­è¨€è½¬æ¢å¤±è´¥")
                return False

        except Exception as e:
            print(f"âŒ Cè¯­è¨€è½¬æ¢å¼‚å¸¸: {e}")
            return False

    def evaluate_model(self):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        if not self.test_results:
            return

        y_test = self.test_results['y_test']
        y_pred = self.test_results['y_pred']
        y_pred_proba = self.test_results['y_pred_proba']

        print("\n=== æ¨¡å‹è¯„ä¼°ç»“æœ ===")
        print(f"å‡†ç¡®ç‡: {accuracy_score(y_test, y_pred):.4f}")
        print(f"AUC: {roc_auc_score(y_test, y_pred_proba):.4f}")
        print("\nåˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_test, y_pred, target_names=['ä½éšœç¢ç‰©', 'é«˜éšœç¢ç‰©']))

        # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        self.plot_confusion_matrix()

    def plot_confusion_matrix(self, title_suffix=""):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        if not self.test_results:
            print("æ— æµ‹è¯•æ•°æ®ï¼Œè·³è¿‡æ··æ·†çŸ©é˜µç»˜åˆ¶")
            return

        y_test = self.test_results['y_test']
        y_pred = self.test_results['y_pred']
        cm = confusion_matrix(y_test, y_pred)

        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['ä½éšœç¢ç‰©', 'é«˜éšœç¢ç‰©'],
                    yticklabels=['ä½éšœç¢ç‰©', 'é«˜éšœç¢ç‰©'])
        plt.title(f'æ··æ·†çŸ©é˜µ{title_suffix}')
        plt.ylabel('çœŸå®æ ‡ç­¾')
        plt.xlabel('é¢„æµ‹æ ‡ç­¾')

        save_path = os.path.join(self.config['plot_dir'], f'confusion_matrix{title_suffix.replace(" ", "_")}.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: {save_path}")
        plt.show()

        return cm

    def plot_feature_importance(self, top_n=20):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§"""
        if self.model is None:
            print("æ¨¡å‹æœªè®­ç»ƒ")
            return

        importance = self.model.feature_importance(importance_type='gain')
        feature_imp = pd.DataFrame({
            'feature': self.feature_names,
            'importance': importance
        }).sort_values('importance', ascending=False)

        plt.figure(figsize=(10, 8))
        sns.barplot(data=feature_imp.head(top_n), x='importance', y='feature')
        plt.title(f'å‰{top_n}ä¸ªé‡è¦ç‰¹å¾')
        plt.xlabel('é‡è¦æ€§')

        save_path = os.path.join(self.config['plot_dir'], f'feature_importance_top{top_n}.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜åˆ°: {save_path}")
        plt.show()

        return feature_imp

    def save_model(self, filepath=None):
        """ä¿å­˜æ¨¡å‹"""
        if self.model is None:
            print("æ¨¡å‹æœªè®­ç»ƒ")
            return None

        if filepath is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filepath = os.path.join(self.config['model_dir'], f'obstacle_classifier_{timestamp}.joblib')

        model_data = {
            'model': self.model,
            'feature_names': self.feature_names,
            'config': self.config,
            'timestamp': datetime.now().isoformat()
        }

        joblib.dump(model_data, filepath)
        print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {filepath}")

        return filepath

    def predict(self, test_filepath, output_filepath=None):
        """é¢„æµ‹æµ‹è¯•æ•°æ®"""
        if self.model is None:
            print("æ¨¡å‹æœªè®­ç»ƒ")
            return None

        print(f"é¢„æµ‹æµ‹è¯•æ•°æ®: {test_filepath}")

        # åŠ è½½æµ‹è¯•æ•°æ®
        test_df = self.load_data(test_filepath)
        test_df_processed = self.feature_engineering(test_df)

        # é¢„æµ‹
        X_test = test_df_processed[self.feature_names]
        y_pred_proba = self.model.predict(X_test, num_iteration=self.model.best_iteration)
        y_pred = (y_pred_proba > 0.5).astype(int)

        # åˆ›å»ºç»“æœ
        results = test_df.copy()

        # æ·»åŠ é¢„æµ‹ç»“æœ
        if 'HeightLabel' in test_df.columns:
            results['True_Label'] = test_df['HeightLabel']

        results['Predicted_HeightLabel'] = y_pred
        results['Prediction_Probability'] = y_pred_proba
        results['Confidence'] = np.abs(y_pred_proba - 0.5) * 2

        if 'HeightLabel' in test_df.columns:
            results['Prediction_Correct'] = (results['True_Label'] == results['Predicted_HeightLabel'])
            results['Error_Type'] = results.apply(
                lambda row: 'Correct' if row['Prediction_Correct'] else
                ('False_Positive' if row['True_Label'] == 0 else 'False_Negative'), axis=1
            )

        # ä¿å­˜ç»“æœ
        if output_filepath is None:
            filename = f"prediction_results_{os.path.splitext(os.path.basename(test_filepath))[0]}.csv"
            output_filepath = os.path.join(self.config['results_dir'], filename)

        self.save_csv(results, output_filepath)

        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\né¢„æµ‹ç»Ÿè®¡:")
        print(f"é¢„æµ‹ä¸ºé«˜éšœç¢ç‰©æ¯”ä¾‹: {y_pred.mean():.2%}")
        print(f"å¹³å‡é¢„æµ‹æ¦‚ç‡: {y_pred_proba.mean():.4f}")

        # å¦‚æœæœ‰çœŸå®æ ‡ç­¾ï¼Œè¿›è¡Œè¯„ä¼°
        if 'HeightLabel' in test_df.columns:
            y_true = test_df['HeightLabel'].values
            accuracy = accuracy_score(y_true, y_pred)
            auc = roc_auc_score(y_true, y_pred_proba)

            print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f}")
            print(f"æµ‹è¯•é›†AUC: {auc:.4f}")

            # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
            test_name = os.path.splitext(os.path.basename(test_filepath))[0]
            self.test_results = {
                'y_test': y_true, 'y_pred': y_pred, 'y_pred_proba': y_pred_proba
            }
            self.plot_confusion_matrix(f"_{test_name}")

        return results

    def load_model(self, filepath):
        """åŠ è½½æ¨¡å‹"""
        try:
            model_data = joblib.load(filepath)
            if isinstance(model_data, dict):
                self.model = model_data['model']
                self.feature_names = model_data['feature_names']
                if 'config' in model_data:
                    self.config.update(model_data['config'])
            else:
                self.model = model_data

            print(f"æ¨¡å‹åŠ è½½æˆåŠŸ: {filepath}")
            print(f"ç‰¹å¾æ•°é‡: {len(self.feature_names)}")
            return True
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False


def quick_run_with_c_conversion(train_file, test_file=None, config=None):
    """å¿«é€Ÿè¿è¡Œå‡½æ•° - å«è‡ªåŠ¨Cè¯­è¨€è½¬æ¢"""
    print("=== éšœç¢ç‰©é«˜åº¦åˆ†ç±»å™¨ - å®Œå…¨æ¸…ç†ç‰ˆæœ¬ ===\n")

    # é»˜è®¤é…ç½®
    default_config = {
        'model_dir': './models_clean',
        'plot_dir': './plots_clean',
        'results_dir': './results_clean',
        'misclassified_dir': './misclassified_clean',
        'c_model_dir': './c_model_clean',
        'auto_convert_to_c': True,
        'test_size': 0.0,  # ä½¿ç”¨å…¨éƒ¨æ•°æ®è®­ç»ƒ
        'random_state': 42,
    }

    if config:
        default_config.update(config)

    # åˆ›å»ºåˆ†ç±»å™¨
    classifier = ObstacleHeightClassifier(default_config)

    # è®­ç»ƒ
    print("1. æ•°æ®åŠ è½½å’Œç‰¹å¾å·¥ç¨‹")
    train_df = classifier.load_data(train_file)
    train_df_processed = classifier.feature_engineering(train_df)

    print("\n2. æ¨¡å‹è®­ç»ƒ")
    classifier.train(train_df_processed)

    # ç‰¹å¾é‡è¦æ€§åˆ†æ
    print("\n3. ç‰¹å¾é‡è¦æ€§åˆ†æ")
    classifier.plot_feature_importance()

    # é¢„æµ‹æµ‹è¯•æ•°æ®
    if test_file and os.path.exists(test_file):
        print("\n4. æµ‹è¯•æ•°æ®é¢„æµ‹")
        classifier.predict(test_file)
    else:
        print("\n4. è·³è¿‡é¢„æµ‹é˜¶æ®µï¼ˆæ— æµ‹è¯•æ–‡ä»¶ï¼‰")

    print("\n=== è¿è¡Œå®Œæˆ ===")
    print(f"ğŸ“Š Pythonæ¨¡å‹æ–‡ä»¶: {classifier.config['model_dir']}")
    print(f"ğŸ”§ Cè¯­è¨€ä»£ç : {classifier.config['c_model_dir']}")

    return classifier


def convert_existing_model_to_c(model_path, output_dir="./c_model_converted"):
    """è½¬æ¢å·²ä¿å­˜çš„.joblibæ¨¡å‹æ–‡ä»¶ä¸ºCè¯­è¨€ä»£ç """
    try:
        # åŠ è½½æ¨¡å‹
        model_data = joblib.load(model_path)
        if isinstance(model_data, dict):
            model = model_data['model']
            feature_names = model_data.get('feature_names', [])
        else:
            model = model_data
            feature_names = []

        print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {model_path}")
        print(f"ğŸ¯ è¾“å‡ºç›®å½•: {output_dir}")

        # åˆ›å»ºè½¬æ¢å™¨å¹¶æ‰§è¡Œè½¬æ¢
        converter = LightGBMToCConverter(model, feature_names, output_dir)
        success = converter.convert()

        return success

    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    # ==================== é…ç½®åŒºåŸŸ ====================

    # æ–‡ä»¶è·¯å¾„é…ç½®
    TRAIN_FILE = r'D:\PythonProject\data\processed_data\train_group1.csv'
    TEST_FILE = r'D:\PythonProject\data\processed_data\train_group2.csv'

    # è¾“å‡ºè·¯å¾„é…ç½®
    OUTPUT_CONFIG = {
        'model_dir': r'D:\PythonProject\model\saved_model_clean',
        'plot_dir': r'D:\PythonProject\results\visualization_results_clean',
        'results_dir': r'D:\PythonProject\results\prediction_results_clean',
        'misclassified_dir': r'D:\PythonProject\results\misclassified_results_clean',
        'c_model_dir': r'D:\PythonProject\c_model',  # Cè¯­è¨€æ¨¡å‹è¾“å‡ºç›®å½•
        'auto_create_dirs': True,
        'encoding': 'utf-8-sig',
        'test_size': 0.0,  # ä½¿ç”¨å…¨éƒ¨æ•°æ®è®­ç»ƒ
        'random_state': 42,
        'save_model': True,
        'auto_convert_to_c': True,  # å¯ç”¨è‡ªåŠ¨è½¬æ¢ä¸ºCè¯­è¨€
    }

    print(f"ğŸš€ å¼€å§‹è¿è¡Œå®Œå…¨æ¸…ç†ç‰ˆéšœç¢ç‰©åˆ†ç±»å™¨...")
    print(f"ğŸ“ Cè¯­è¨€æ¨¡å‹å°†ä¿å­˜åœ¨: {OUTPUT_CONFIG['c_model_dir']}")
    print(f"{'=' * 80}")

    try:
        # æ£€æŸ¥è®­ç»ƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(TRAIN_FILE):
            print(f"âŒ è®­ç»ƒæ–‡ä»¶ä¸å­˜åœ¨: {TRAIN_FILE}")
            print(f"è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
            exit(1)

        # è¿è¡Œåˆ†ç±»å™¨
        classifier = quick_run_with_c_conversion(TRAIN_FILE, TEST_FILE, OUTPUT_CONFIG)

        print(f"\n{'=' * 80}")
        print(f"âœ… è®­ç»ƒå’Œè½¬æ¢å®Œæˆï¼")
        print(f"\nğŸ“Š Pythonæ¨¡å‹å’Œç»“æœ:")
        print(f"   - æ¨¡å‹æ–‡ä»¶: {OUTPUT_CONFIG['model_dir']}")
        print(f"   - å¯è§†åŒ–ç»“æœ: {OUTPUT_CONFIG['plot_dir']}")
        print(f"   - é¢„æµ‹ç»“æœ: {OUTPUT_CONFIG['results_dir']}")

        print(f"\nğŸ”§ Cè¯­è¨€æ¨¡å‹:")
        print(f"   - Cä»£ç ç›®å½•: {OUTPUT_CONFIG['c_model_dir']}")
        print(f"   - ç¼–è¯‘å‘½ä»¤: cd {OUTPUT_CONFIG['c_model_dir']} && make")
        print(f"   - è¿è¡Œæµ‹è¯•: cd {OUTPUT_CONFIG['c_model_dir']} && ./test_obstacle_height")

        # éªŒè¯Cè¯­è¨€æ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
        c_files = ['obstacle_height_model.h', 'obstacle_height_model.c', 'test_obstacle_height.c', 'Makefile']
        missing_files = []

        for filename in c_files:
            filepath = os.path.join(OUTPUT_CONFIG['c_model_dir'], filename)
            if not os.path.exists(filepath):
                missing_files.append(filename)
            else:
                size = os.path.getsize(filepath)
                print(f"   âœ… {filename} ({size} bytes)")

        if missing_files:
            print(f"\nâš ï¸  è­¦å‘Š: ä»¥ä¸‹Cè¯­è¨€æ–‡ä»¶æœªç”Ÿæˆ: {missing_files}")
        else:
            print(f"\nğŸ‰ æ‰€æœ‰Cè¯­è¨€æ–‡ä»¶å·²æˆåŠŸç”Ÿæˆ!")
            print(f"\nğŸ“ ä¸‹ä¸€æ­¥:")
            print(f"   1. è¿›å…¥Cæ¨¡å‹ç›®å½•: cd {OUTPUT_CONFIG['c_model_dir']}")
            print(f"   2. ç¼–è¯‘é¡¹ç›®: make")
            print(f"   3. è¿è¡Œæµ‹è¯•: ./test_obstacle_height")

    except FileNotFoundError as e:
        print(f"\nâŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        print(f"ğŸ”§ è¯·æ£€æŸ¥:")
        print(f"   1. è®­ç»ƒæ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {TRAIN_FILE}")
        print(f"   2. æµ‹è¯•æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {TEST_FILE}")

    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        print(f"\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print(f"   1. æ£€æŸ¥Pythonç¯å¢ƒå’Œä¾èµ–åŒ…")
        print(f"   2. æ£€æŸ¥æ•°æ®æ–‡ä»¶æ ¼å¼å’Œå†…å®¹")
        print(f"   3. æ£€æŸ¥è¾“å‡ºç›®å½•æƒé™")

    print(f"\nğŸ ç¨‹åºç»“æŸ")